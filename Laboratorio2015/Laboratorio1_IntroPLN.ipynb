{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: 2015-11-23 18:35:30.577963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fkauffman\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "# Se importan las librerias correspondientes\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas\n",
    "import numpy as np\n",
    "import utils_pln as utl # Archivo con utilitarios, los mismos se separaron del notebook para no sobrecargarlo\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "import datetime\n",
    "\n",
    "print(\"START: \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importamos el corpus de comentarios\n",
    "\n",
    "Pandas es una biblioteca de código abierto implementada en Python la cual permite realizar una fácil manipulación y análisis de los datos.\n",
    "Esta se utilizó para cargar los datos en memoria y realizar un breve análisis de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se carga en 'datos' el archivo csv en memoria\n",
    "datos = pandas.read_csv(\"comentarios_peliculas.csv\", skiprows=1, delimiter=';', skip_blank_lines=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Características del corpus\n",
    "Para conocer acerca del corpus sobre el cual se trabajará se realiza un breve análisis de los datos. Para ello se obtiene la cantidad de filas y columnas que el dataset posee; donde las filas corresponden a los comentarios y las columnas a los atributos asociados a los mismos. Por otro lado se obtiene la cantidad de peliculas del corpus, la cantidad de comentarios para cada película, en el que se realiza un ploteo, entre otros. A su vez se listan esos atributos junto a su tipo asociado. Una vez hecho esto se procede a chequear de que los atributos de los comentarios tengan o no valores faltantes, ya que en caso de tenerlos hay que tomar una decisión en base a qué hacer con los mismos (existen varias técnicas para este tratamiento). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay una cantidad de 127 películas en el corpus.\n",
      "El corpus posee 1447 comentarios con 9 atributos por cada uno de ellos.\n",
      "\n",
      "Cantidad de comentarios asociados a cada película:\n",
      "\n",
      "Relatos salvajes                                      69\n",
      "A 60 km/h                                             55\n",
      "Mr. Kaplan                                            49\n",
      "Cincuenta sombras de Grey                             46\n",
      "Sin hijos                                             41\n",
      "El Gran Hotel Budapest                                36\n",
      "23 segundos                                           35\n",
      "Intensa-Mente                                         32\n",
      "Directo al corazón                                    28\n",
      "Tus padres volverán                                   26\n",
      "El planeta de los simios: confrontación               26\n",
      "Betibú                                                24\n",
      "Maléfica                                              21\n",
      "Noé                                                   21\n",
      "Luna de miel en familia                               21\n",
      "Guardianes de la Galaxia                              21\n",
      "La dama de oro                                        20\n",
      "Operación Monumento                                   20\n",
      "Mundo Jurásico                                        20\n",
      "Avant                                                 20\n",
      "Cómo entrenar a tu dragón 2                           20\n",
      "Bajo la misma estrella                                20\n",
      "Búsqueda implacable 3                                 20\n",
      "Avengers: era de Ultrón                               19\n",
      "Rápidos y furiosos 7                                  18\n",
      "Mad Max: furia en el camino                           18\n",
      "Las aventuras de Peabody y Sherman                    18\n",
      "Non-Stop: sin escalas                                 18\n",
      "El padre de Gardel                                    18\n",
      "Rio 2                                                 17\n",
      "                                                      ..\n",
      "Mujeres al ataque!                                     4\n",
      "Dos locas en fuga                                      3\n",
      "Pompeii                                                3\n",
      "Código Sombra: Jack Ryan                               3\n",
      "Poltergeist: juegos diabólicos                         3\n",
      "Osos                                                   3\n",
      "Violetta: En Concierto                                 3\n",
      "La leyenda de Hércules                                 3\n",
      "Los 4 Fantásticos                                      3\n",
      "Cobain - Montage of Heck                               2\n",
      "True Detective                                         2\n",
      "Cine Arte del Sodre - Los Musicales                    2\n",
      "Plano Americano: charlas entre cineastas uruguayos     2\n",
      "Cine Arte del Sodre - Cine de Matinée                  2\n",
      "Resucitados                                            2\n",
      "Las novias de mis amigos                               2\n",
      "La Murga, ópera popular                                1\n",
      "15 Festival Internacional de Escuelas de Cine          1\n",
      "Domingos Cerrados – Cine y Gastronomía                 1\n",
      "Cineclub CCE - Lo diferente no es peor                 1\n",
      "McFarland: Sin límites                                 1\n",
      "El viaje más largo                                     1\n",
      "Heredero del diablo                                    1\n",
      "Aviones 2: equipo de rescate                           1\n",
      "Un golpe de talento                                    1\n",
      "La Pedrera Short Film Festival #11                     1\n",
      "Muppets 2: los más buscados                            1\n",
      "In-actividad paranormal                                1\n",
      "1ª Muestra de Avant Premières de Cine Francés          1\n",
      "Cine Arte del Sodre: Los Musicales 2                   1\n",
      "Name: Título, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Se obtiene cantidad peliculas, de comentarios y cantidad de atributos\n",
    "cantPeliculas = len(datos.ix[:,0].unique())\n",
    "cantComentarios = len(datos.index)\n",
    "cantAtributos = len(datos.columns)\n",
    "\n",
    "# Se imprimen los datos obtenidos anteriormente junto a sus tipos de datos\n",
    "print (\"Hay una cantidad de \" + str(cantPeliculas) + \" películas en el corpus.\")\n",
    "print (\"El corpus posee \" + str(cantComentarios) + \" comentarios con \" + str(cantAtributos) + \" atributos por cada uno de ellos.\")\n",
    "\n",
    "# Se imprime la cantidad de comentarios para cada pelicula\n",
    "print (\"\\nCantidad de comentarios asociados a cada película:\\n\")\n",
    "print (datos.ix[:,0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEZCAYAAACQK04eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzczGzP8HJTwThvDWTOgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xae96e19fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se importa la libreria para utilizar plot\n",
    "# Además se plotea en el própio notebook y no como una ventana nueva\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "\n",
    "# Se realiza una gráfica de cantidad de comentarios en función de su clasificación\n",
    "gruposCalificacion = datos.groupby([u'Calificación']).groups\n",
    "keyClasificacion = gruposCalificacion.keys()\n",
    "cantClasificacion = []\n",
    "for k in keyClasificacion:\n",
    "    cantClasificacion.append(len(gruposCalificacion.get(k)))    \n",
    "pos = arange(len(keyClasificacion)) + 0.5 \n",
    "\n",
    "figure(1)\n",
    "barh(pos,cantClasificacion, align='center')\n",
    "yticks(pos, list(keyClasificacion))\n",
    "xlabel('Cantidad de comentarios')\n",
    "ylabel(u'Clasificación')\n",
    "title(u'Grafica cantidad de comentarios por clasificación')\n",
    "grid(True)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de comentarios asociados a cada calificación:\n",
      "\n",
      "5    505\n",
      "4    354\n",
      "1    225\n",
      "3    222\n",
      "2    141\n",
      "Name: Calificación, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Se imprime la cantidad de comentarios asociados a cada clase (es decir cantidad de comentarios por calificación)\n",
    "print (\"\\nCantidad de comentarios asociados a cada calificación:\\n\")\n",
    "print (datos.ix[:,7].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A continuación se listan los atributos con su tipo asociado:\n",
      "\n",
      "Título          object\n",
      "Año              int64\n",
      "Estrellas        int64\n",
      "Género          object\n",
      "Duración        object\n",
      "Reseña          object\n",
      "ComTexto        object\n",
      "Calificación     int64\n",
      "ComFechaHora    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (\"A continuación se listan los atributos con su tipo asociado:\\n\")\n",
    "print (datos.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay valores faltantes para el tributo Título\n",
      "No hay valores faltantes para el tributo Año\n",
      "No hay valores faltantes para el tributo Estrellas\n",
      "No hay valores faltantes para el tributo Género\n",
      "No hay valores faltantes para el tributo Duración\n",
      "No hay valores faltantes para el tributo Reseña\n",
      "No hay valores faltantes para el tributo ComTexto\n",
      "No hay valores faltantes para el tributo Calificación\n",
      "No hay valores faltantes para el tributo ComFechaHora\n"
     ]
    }
   ],
   "source": [
    "# Se chequea si los atributos poseen o no valores faltantes\n",
    "# Para ello se recorren todos los atributos (columnas de 'datos')\n",
    "for atributo in datos.columns:\n",
    "    \n",
    "    # Se obtiene la cantidad de valores distinto de vacio del atributo \n",
    "    cantValoresAtributo = datos[atributo].describe()['count']\n",
    "    \n",
    "    # Si hay menos que la cantidad de comentarios de 'datos' -> hay valores faltantes\n",
    "    if(cantComentarios > cantValoresAtributo):\n",
    "        print (\"Hay valores faltantes para el atributo \" + atributo)\n",
    "    else:\n",
    "        print (\"No hay valores faltantes para el tributo \" + atributo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Descartamos columnas innecesarias\n",
    "En esta sección se descartan las columnas (atributos) que se consideran innecesarios. En particular las columnas que creemos se consideran necesarias son solamente las columnas de los comentarios y los puntajes asociados a dichos comentarios. Por lo que se procede a eliminar el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               ComTexto  Calificación\n",
      "0     Muchas gracias, vi online los primeros 4, lueg...             4\n",
      "1           La mejor serie desde Los Soprano y The Wire             5\n",
      "2     Llega un punto en el que aburre. Es un plato b...             2\n",
      "3     En realidad no es una respuesta , es una corre...             1\n",
      "4     Ahora entiendo menos. El libro en que se basa ...             1\n",
      "5     Una pena desperdiciar un buen elenco y obviame...             1\n",
      "6     MAGISTRAL!! excelente la recreación de época. ...             5\n",
      "7                             es una película mui padre             5\n",
      "8     EXCELENTE! GENIAL! Esperaba ir a ver con mi hi...             5\n",
      "9     Muy, muy buena...para grandes y chicos. Tiene ...             5\n",
      "10    Excelente película, muy original y divertida. ...             5\n",
      "11    Muy buena película, muy graciosa y de humor ba...             4\n",
      "12    Muy linda película. La fui a ver con mi hija, ...             4\n",
      "13    Linda película, buen mensaje y muy buenos efec...             4\n",
      "14    tambien me encanto la pelicula tu comentario e...             5\n",
      "15    la mejor peli que vi no hay ninguna cosa mejor...             5\n",
      "16    Excelente pelicula. Seguramente sea una de las...             4\n",
      "17    Pelicula propaganda. Resumen de la trama: USA ...             1\n",
      "18                        Muy buena pelicula de accion.             4\n",
      "19    Otro film de accion sostenido por Kevin Costne...             2\n",
      "20                Un bayago, no gasten un peso en esto.             1\n",
      "21    Qué nos queda si a Spartacus le sacamos la san...             2\n",
      "22    Bastante entretenida y absolutamente olvidable...             2\n",
      "23    pelicula aburrida en algunas ecsenas pero con ...             3\n",
      "24    Excelente, como todas las películas de Marvel,...             5\n",
      "25                                             la rompe             5\n",
      "26    Excelente pelicula desde todo punto de vistas,...             4\n",
      "27    Cumple sobradamente lo que promete. Y no hablo...             4\n",
      "28    muy buena, pero el 3d aun no esta bien logrado...             4\n",
      "29    Excelente película! Un enfoque distinto a lo q...             5\n",
      "...                                                 ...           ...\n",
      "1417  Me encantó la película, me emocionó hasta el b...             5\n",
      "1418  Aceptable, por momentos conmovedora y emotiva,...             2\n",
      "1419  Tuve la oportunidad de ver la película y me ag...             5\n",
      "1420  A mí la película me gustó mucho. Su realizació...             5\n",
      "1421  Fui al estreno en día de ayer...y la verdad me...             5\n",
      "1422  Excelente. Sin palabras. Una película muy sens...             5\n",
      "1423  Si estás buscando algo distinto esta es la pel...             5\n",
      "1424  Al fin veo una película de la época de la dict...             5\n",
      "1425  Lo siento pero creo que vimos películas comple...             5\n",
      "1426  Véanla!!! No se la pueden perder. Muy interesa...             5\n",
      "1427  La vi anoche, tenía espectativa, una pena, no ...             1\n",
      "1428  Excelente!!! Te mantiene expectante de princip...             5\n",
      "1429  La tres para mi es la mejor, Pero esta buena, ...             3\n",
      "1430  Entretenida, con humor de principio a fin. Ale...             3\n",
      "1431  Buena película de acción, con hermosas vistas ...             4\n",
      "1432  Buena para lo que son las peliculas de aventur...             4\n",
      "1433  Buena pelicula de acción.  Si viste las anteri...             3\n",
      "1434                         Mediocre, no aporta mucho.             2\n",
      "1435  MUY BUENA PELICULA Y MUY ACTUAL DEMUESTRA LO P...             4\n",
      "1436  Esta bien personalmente me gusto ,a pesar que ...             3\n",
      "1437  Aceptable, bien los actores, la trama se basa ...             2\n",
      "1438  Fui con unas amigas, no nos dejaron entrar x n...             1\n",
      "1439  Malísima. No esperaba que fuera mejor que el l...             1\n",
      "1440  me gusto pero no es que me encanto porque la v...             3\n",
      "1441  Lenta. No es lo que esperaba ni mucho menos. L...             1\n",
      "1442                    Mala. Muy lenta. Sin argumento.             2\n",
      "1443  No es buena, pasan 80% de la película introduc...             1\n",
      "1444  Mala. Malísima. No vale ni verla por la tele. ...             1\n",
      "1445  La peor película de Marvel de los últimos tiem...             1\n",
      "1446                                    Qué buenisimo!!             5\n",
      "\n",
      "[1447 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Se descartan de 'datos' las columnas innecesarias, dejando solamente los comentarios y sus calificaciones\n",
    "datos.drop(datos.columns[[0,1,2,3,4,5,8]],inplace=True,axis=1)\n",
    "comentarios_peliculas = datos\n",
    "# Se imprime un resumen de los datos\n",
    "print (comentarios_peliculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocesamiento de los comentarios\n",
    "El corpus sobre el cual se trabaja puede contener datos con ruido en su contenido. Es decir, diversos elementos que están mezclados en el contenido pero que además de que no aportan nada a la tarea de clasificación, generan ruido dificultando las tareas posteriores. Para ello entonces se procede a realizar el preprocesamiento de los comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se limpian los datos y se los convierte a una lista de tuplas para su facil manipualacion.\n",
    "comentarios_peliculas = utl.convert_to_list(utl.depurar_comentarios(comentarios_peliculas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Separamos entrenamiento y testeo \n",
    "Una vez llegado este punto se divide la lista obtenida en el paso anterior en conjuntos de entrenamiento y testeo, para primero entrenar el algoritmo y luego testearlo.\n",
    "Para poder entrenar y testear un algoritmo de aprendizaje, como se mencionó, es necesario primero particionar los datos en dos conjuntos disjuntos de entrenamiento y testeo. Se separarán aleatoriamente un 20% de los datos para testeo y el 80% restante se utilizará para el entrenamiento. Para esto se utilizó la función train_test_split del paquete cross_validation de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "# Se divide el conjunto de datos en train (80%) y test (20%)\n",
    "datos_train, datos_test = train_test_split(comentarios_peliculas, test_size=0.2)\n",
    "\n",
    "# Se chequean las cantidades de la división\n",
    "print (len(datos_train))\n",
    "print (len(datos_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tokenización NLTK\n",
    "En esta sección se realiza el proceso de tokenización de los textos utilizando la biblioteca NLTK. Además se convierte a un formato suceptible para la clasificación. Es decir, se tokenizan los comentarios y se calcula el diccionario de palabras frecuentes del mismo. En base a ello y al valor de clasificación asociado se crea una tupla la cual corresponde al comentario analizado. Luego estas tuplas (una por cada comentario) son la entrada para el entrenamiento del algoritmo Entropía Máxima provisto por NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'ampliamente': 1, ',': 1, ')': 1, 'rápido': 1, 'recomendable': 1, 'cine': 1, 'fin': 1, 'bien': 1, 'en': 1, 'del': 1, 'tiempos': 1, 'película': 1, 'actuaciones': 1, 'la': 1, 'film': 1, 'las': 1, 'ironía': 1, 'y': 1, 'también': 1, 'estos': 1, 'mega': 1, 'están': 1, 'por': 1, '!': 2, 'musicalización': 1, 'tarde': 1, '(': 1, 'buena': 1, 'furioso': 1, 'eventos': 1, '.': 4, 'de': 2, 'excelente': 1, 'como': 2, 'una': 1, 'muy': 2, 'así': 1, 'socioculturales': 1, 'buen': 1}, 'pos')\n"
     ]
    }
   ],
   "source": [
    "datos_train_tokenizados_nltk = utl.tokenizar_nltk(datos_train)\n",
    "\n",
    "#Se imprime el primer comentario tokenizado, cada palabra aparece junto a la cantidad de veces\n",
    "# que ocurre en el comentario y ademas se imprime la clasificacion del comentario.\n",
    "print (datos_train_tokenizados_nltk[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Entrenamiento y evaluación\n",
    "Una vez de tener los datos en un formato aceptable para los algoritmos de entrenamiento y particionado los mismos en test y train, se procede a realizar el entrenamiento del algoritmo de Máxima Entropía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (8 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.589\n",
      "             2          -0.80447        0.750\n",
      "             3          -0.67249        0.814\n",
      "             4          -0.58510        0.864\n",
      "             5          -0.52269        0.882\n",
      "             6          -0.47562        0.890\n",
      "             7          -0.43870        0.900\n",
      "         Final          -0.40887        0.909\n"
     ]
    }
   ],
   "source": [
    "# En la siguiente linea se entrena el algoritmo con 8 iteraciones\n",
    "# Obs. El entrenamiento es bastante lento.\n",
    "clf_max_ent = nltk.classify.MaxentClassifier.train(datos_train_tokenizados_nltk,max_iter=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluacion del clasificador con los datos de test\n",
    "Luego del entrenamiento se procede a evaluar el clasificador con los datos de test, y se obtiene la matriz de confusión para poder analizar claramente los resultados, calculando la accuracy, la precisión, recall y medida F (Esto se realiza en la función getTasa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "    |   n   n   p |\n",
      "    |   e   e   o |\n",
      "    |   g   u   s |\n",
      "----+-------------+\n",
      "neg | <39> 16  24 |\n",
      "neu |   .  <3>  1 |\n",
      "pos |  28  27<152>|\n",
      "----+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy:\n",
      "0.6689655172413793\n",
      "Precisión:\n",
      "\tPos: 0.7342995169082126\n",
      "\tNeu: 0.75\n",
      "\tNeg: 0.4936708860759494\n",
      "Recall:\n",
      "\tPos: 0.8587570621468926\n",
      "\tNeu: 0.06521739130434782\n",
      "\tNeg: 0.582089552238806\n",
      "F-Score:\n",
      "\tPos: 0.7916666666666667\n",
      "\tNeu: 0.12\n",
      "\tNeg: 0.5342465753424658\n"
     ]
    }
   ],
   "source": [
    "#Se imprime la tasa de acierto y la matriz de confucion\n",
    "datos_test_tokenizado_nltk = utl.tokenizar_nltk(datos_test)\n",
    "utl.getTasa(clf_max_ent,datos_test_tokenizado_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la matriz de confusión los resultados para las tres clases aún se podrían mejorar, para esto incorporaremos diferentes tipos de features y utilizaremos otras formas de tokenización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Incorporación de Features\n",
    "#### Palabras más frecuentes\n",
    "En esta sección se busca mejorar el clasificador utilizando como features las palabras más frecuentes, para esto se cuentan las palabras del corpus y se calcula su frecuencia. \n",
    "Se utiliza cross-validation para ajustar la cantidad de palabras más frecuentes que se utilizarán para el clasificador. Con el objetivo anterior se definen varias cantidades de palabras y se prueba con cada una de ellas, calculando un promedio del accuracy obtenido en cada iteración del cross-validation.\n",
    "\n",
    "Obs.: Este proceso demora mucho tiempo en realizarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross valodation para el clasificador\n",
    "# Frecuencia -1 significa todas las palabras\n",
    "fecuencias = [-1, 5000, 3000, 2000, 1000, 500]\n",
    "\n",
    "accuracy_frec_cv = []\n",
    "\n",
    "for frec in fecuencias:\n",
    "    print('******************************************************************************')\n",
    "    print(\"FRECUENCIA: \" + str(frec))\n",
    "    \n",
    "    datos_train_frec = utl.filtrar(datos_train, utl.palabras_mas_frecuentes(frec,datos_train), False)\n",
    "    datos_train_tokenizados = utl.tokenizar_nltk(datos_train_frec)\n",
    "    \n",
    "    cv = cross_validation.KFold(len(datos_train_tokenizados), n_folds=10)\n",
    "    \n",
    "    accuracy = 0\n",
    "    for traincv, evalcv in cv:\n",
    "        classifier = nltk.classify.MaxentClassifier.train(datos_train_tokenizados[traincv[0]:traincv[len(traincv)-1]],max_iter=8,trace=1)\n",
    "        accuracy += nltk.classify.util.accuracy(classifier, datos_train_tokenizados[evalcv[0]:evalcv[len(evalcv)-1]])\n",
    "        \n",
    "    accuracy_avg = (accuracy / 10)\n",
    "    accuracy_frec_cv += [(frec,accuracy_avg)]\n",
    "    print('ACCURACY: ' + str(accuracy_avg))\n",
    "print (accuracy_frec_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al finalizar el cross-validation, se calcula la cantidad de palabras que tuvo mayor accuracy promedio y se toma dicha cantidad como la cantidad óptima de palabras frecuentes. Una vez obtenido este valor, se filtran los comentarios del corpus de entrenamiento, dejando, para cada comentario, únicamente las palabras que se encuentran dentro de las palabras más frecuentes del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor cantidad de palabras frecuentes: -1\n"
     ]
    }
   ],
   "source": [
    "best_frec = utl.getBestFrec(accuracy_frec_cv)\n",
    "print(\"Mejor cantidad de palabras frecuentes: \" + str(best_frec))\n",
    "palabras_mas_frecuentes = utl.palabras_mas_frecuentes(best_frec,datos_train)\n",
    "datos_train_frec = utl.filtrar(datos_train, palabras_mas_frecuentes, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en el resultado anterior, la variable best_frec obtuvo el valor -1, el cual indica que la cantidad óptima de palabras son todas las palabras del corpus.\n",
    "\n",
    "Luego, se entrena un nuevo clasificador con el corpus de entrenamiento (comentarios conformados únicamente por las palabras más frecuentes del corpus) y se procede a evaluar el clasificador con el corpus de testeo como se hizo previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (8 iterations)\n",
      "Matriz de confusión:\n",
      "    |   n   n   p |\n",
      "    |   e   e   o |\n",
      "    |   g   u   s |\n",
      "----+-------------+\n",
      "neg | <29>  8   9 |\n",
      "neu |   .  <2>  1 |\n",
      "pos |  38  36<167>|\n",
      "----+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy:\n",
      "0.6827586206896552\n",
      "Precisión:\n",
      "\tPos: 0.6929460580912863\n",
      "\tNeu: 0.6666666666666666\n",
      "\tNeg: 0.6304347826086957\n",
      "Recall:\n",
      "\tPos: 0.943502824858757\n",
      "\tNeu: 0.043478260869565216\n",
      "\tNeg: 0.43283582089552236\n",
      "F-Score:\n",
      "\tPos: 0.7990430622009568\n",
      "\tNeu: 0.08163265306122448\n",
      "\tNeg: 0.5132743362831859\n"
     ]
    }
   ],
   "source": [
    "datos_train_tokenizados_nltk = utl.tokenizar_nltk(datos_train_frec)\n",
    "    \n",
    "classifier = nltk.classify.MaxentClassifier.train(datos_train_tokenizados_nltk,max_iter=8,trace=1)\n",
    "utl.getTasa(classifier,datos_test_tokenizado_nltk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar en los resultados obtenidos, estos son similares a los anteriores, como era de esperarse.\n",
    "\n",
    "A partir de este momento, se utilizarán las n palabras más frecuentes, donde n es la mejor cantidad de palabras frecuentes ajustada mediante cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elementos subjetivos\n",
    "A continuación se incorporan como features los elementos subjetivos provistos por los docentes. Para esto se importan desde el archivo \"elementos_subjetivos.txt\" y se los transforma dejándolos en el mismo formato que el corpus de entrenamiento y se agregan a dicho corpus como comentarios de una única palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "elementos_subjetivos = utl.codificarClasificacionesSubjetivos(utl.diccionarioElementosSubjetivos(\"elementos_subjetivos.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nltk = datos_train_tokenizados_nltk + elementos_subjetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena un clasificador con el nuevo corpus de entrenamiento y se procede a la evaluación de dicho clasificador con el corpus de testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (8 iterations)\n",
      "Matriz de confusión:\n",
      "    |   n   n   p |\n",
      "    |   e   e   o |\n",
      "    |   g   u   s |\n",
      "----+-------------+\n",
      "neg | <28> 11  13 |\n",
      "neu |   .  <2>  1 |\n",
      "pos |  39  33<163>|\n",
      "----+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy:\n",
      "0.6655172413793103\n",
      "Precisión:\n",
      "\tPos: 0.6936170212765957\n",
      "\tNeu: 0.6666666666666666\n",
      "\tNeg: 0.5384615384615384\n",
      "Recall:\n",
      "\tPos: 0.9209039548022598\n",
      "\tNeu: 0.043478260869565216\n",
      "\tNeg: 0.417910447761194\n",
      "F-Score:\n",
      "\tPos: 0.79126213592233\n",
      "\tNeu: 0.08163265306122448\n",
      "\tNeg: 0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.classify.MaxentClassifier.train(features_nltk,max_iter=8,trace=1)\n",
    "utl.getTasa(classifier,datos_test_tokenizado_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar en los resultados obtenidos, estos vuelven a ser similares a los anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Tokenización Freeling\n",
    "Ahora se procede a realizar la tokenización utilizando Freeling.\n",
    "\n",
    "Según nuestras observaciones el resultado de esta tokenización es muy similar al obtenido durante la tokenización con NLTK, pero es posible que la tokenización con Freeling sea más precisa, debido a que es una herramienta que está hecha específicamente para el idioma español.\n",
    "\n",
    "Para probar la tokenización con Freeling, se agregaron al corpus de entrenamiento las mismas features que anteriormente (palabras más frecuentes y elementos subjetivos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (8 iterations)\n",
      "Matriz de confusión:\n",
      "    |   n   n   p |\n",
      "    |   e   e   o |\n",
      "    |   g   u   s |\n",
      "----+-------------+\n",
      "neg | <30> 11  13 |\n",
      "neu |   .  <2>  . |\n",
      "pos |  37  33<164>|\n",
      "----+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy:\n",
      "0.6758620689655173\n",
      "Precisión:\n",
      "\tPos: 0.7008547008547008\n",
      "\tNeu: 1.0\n",
      "\tNeg: 0.5555555555555556\n",
      "Recall:\n",
      "\tPos: 0.9265536723163842\n",
      "\tNeu: 0.043478260869565216\n",
      "\tNeg: 0.44776119402985076\n",
      "F-Score:\n",
      "\tPos: 0.7980535279805352\n",
      "\tNeu: 0.08333333333333333\n",
      "\tNeg: 0.4958677685950414\n"
     ]
    }
   ],
   "source": [
    "datos_train_tokenizados_freeling = utl.tokenizar_freeling(datos_train_frec)\n",
    "datos_test_tokenizados_freeling = utl.tokenizar_freeling(datos_test)\n",
    "\n",
    "features_freeling = datos_train_tokenizados_freeling + elementos_subjetivos\n",
    "\n",
    "classifier = nltk.classify.MaxentClassifier.train(features_freeling,max_iter=8,trace=1)\n",
    "utl.getTasa(classifier,datos_test_tokenizados_freeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. POS-tagging\n",
    "El siguiente paso en nuestra investigación es repetir el proceso anterior pero agregando información de POS-tagging.\n",
    "\n",
    "Esta información agregada la utilizamos para descartar tipos de palabras que no afectan a la hora de clasificar un comentario, como podrían ser los artículos, los nombres, etc.\n",
    "\n",
    "Luego de esto, se entrena un nuevo clasificador y se evalúa su accuracy.\n",
    "\n",
    "Obs.: En la función POS_tagging se encuentra las etiquetas EAGLES utilizadas para la selección de las features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-500566709231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTDOUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatos_train_tokenizados_pos_tagging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOS_tagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos_train_frec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdatos_test_tokenizados_pos_tagging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOS_tagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures_pos_tagging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatos_train_tokenizados_pos_tagging\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0melementos_subjetivos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utl' is not defined"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "datos_train_tokenizados_pos_tagging = utl.POS_tagging(datos_train_frec)\n",
    "datos_test_tokenizados_pos_tagging = utl.POS_tagging(datos_test)\n",
    "\n",
    "features_pos_tagging = datos_train_tokenizados_pos_tagging + elementos_subjetivos\n",
    "\n",
    "classifier = nltk.classify.MaxentClassifier.train(features_pos_tagging,max_iter=8,trace=1)\n",
    "utl.getTasa(classifier,datos_test_tokenizados_pos_tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien el accuracy de la última ejecución fue inferior al escenario anterior, en promedio, al agregar información de POS-tagging la accuracy del clasificador mejoró, debido a que esto permitió ser más riguroso con la selección de las features.\n",
    "\n",
    "En las pruebas realizadas los valores oscilaron entre 0.67 y 0.74."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Incorporación de otras features\n",
    "Para intentar mejorar nuestro clasificador incorporamos otras features. Las features agregadas fueron:\n",
    "\n",
    "- Términos no valorativos del ámbito del cine: Palabras que se pueden encontrar en un comentario sobre una película pero que no aportan a la hora de clasificar dicho comentario.\n",
    "- Caracteres especiales y signos de puntuación: Al ver las palabras más frecuentes del corpus, nos encontramos con que las palabras más frecuentes eran siempre signos de puntuación como (\"!\", \".\", \",\", etc), por lo que pensamos que se podría mejorar la precisión descartándolos.\n",
    "- Stopwords: Stopwords del español provistas por NLTK.\n",
    "\n",
    "\n",
    "Luego de la incorporación de estas features, se vuelve a probar con las tres opciones de tokenización previamente utilizadas (NLTK, Freeling, con información de POS-tagging), y verificar si se mejora la precisión con estas incorporaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominio_cine_peliculas = open('terminosNoValorativosAmbitoCine.txt').read()\n",
    "caracteres_especiales = open('caracteres_especiales.txt').read()\n",
    "nltk_stopwords = stopwords.words('spanish')\n",
    "\n",
    "datos_train_frec = utl.filtrar(datos_train_frec, nltk_stopwords, True)\n",
    "datos_train_frec = utl.filtrar(datos_train_frec, caracteres_especiales, True)\n",
    "datos_train_frec = utl.filtrar(datos_train_frec, dominio_cine_peliculas, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (8 iterations)\n",
      "Matriz de confusión:\n",
      "    |   n   n   p |\n",
      "    |   e   e   o |\n",
      "    |   g   u   s |\n",
      "----+-------------+\n",
      "neg | <30>  7   8 |\n",
      "neu |   6  <9>  4 |\n",
      "pos |  31  30<165>|\n",
      "----+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy:\n",
      "0.7034482758620689\n",
      "Precisión:\n",
      "\tPos: 0.7300884955752213\n",
      "\tNeu: 0.47368421052631576\n",
      "\tNeg: 0.6666666666666666\n",
      "Recall:\n",
      "\tPos: 0.9322033898305084\n",
      "\tNeu: 0.1956521739130435\n",
      "\tNeg: 0.44776119402985076\n",
      "F-Score:\n",
      "\tPos: 0.8188585607940446\n",
      "\tNeu: 0.2769230769230769\n",
      "\tNeg: 0.5357142857142857\n"
     ]
    }
   ],
   "source": [
    "datos_train_tokenizados_nltk = utl.tokenizar_nltk(datos_train_frec)\n",
    "datos_test_tokenizado_nltk = utl.tokenizar_nltk(datos_test)\n",
    "\n",
    "features_nltk = datos_train_tokenizados_nltk + elementos_subjetivos\n",
    "\n",
    "classifier = nltk.classify.MaxentClassifier.train(datos_train_tokenizados_nltk,max_iter=8,trace=1)\n",
    "utl.getTasa(classifier,datos_test_tokenizado_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (8 iterations)\n",
      "Matriz de confusión:\n",
      "    |   n   n   p |\n",
      "    |   e   e   o |\n",
      "    |   g   u   s |\n",
      "----+-------------+\n",
      "neg | <43> 12  20 |\n",
      "neu |   .  <5>  2 |\n",
      "pos |  24  29<155>|\n",
      "----+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy:\n",
      "0.7\n",
      "Precisión:\n",
      "\tPos: 0.7451923076923077\n",
      "\tNeu: 0.7142857142857143\n",
      "\tNeg: 0.5733333333333334\n",
      "Recall:\n",
      "\tPos: 0.8757062146892656\n",
      "\tNeu: 0.10869565217391304\n",
      "\tNeg: 0.6417910447761194\n",
      "F-Score:\n",
      "\tPos: 0.8051948051948052\n",
      "\tNeu: 0.18867924528301885\n",
      "\tNeg: 0.6056338028169014\n"
     ]
    }
   ],
   "source": [
    "#FREELING\n",
    "datos_train_tokenizados_freeling = utl.tokenizar_freeling(datos_train_frec)\n",
    "datos_test_tokenizados_freeling = utl.tokenizar_freeling(datos_test)\n",
    "\n",
    "features_freeling = datos_train_tokenizados_freeling + elementos_subjetivos\n",
    "\n",
    "classifier = nltk.classify.MaxentClassifier.train(features_freeling,max_iter=8,trace=1)\n",
    "utl.getTasa(classifier,datos_test_tokenizados_freeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS-tagging\n",
    "datos_train_tokenizados_pos_tagging = utl.POS_tagging(datos_train_frec)\n",
    "datos_test_tokenizados_pos_tagging = utl.POS_tagging(datos_test)\n",
    "\n",
    "features_POS_tagging = datos_train_tokenizados_pos_tagging + elementos_subjetivos\n",
    "\n",
    "classifier = nltk.classify.MaxentClassifier.train(features_POS_tagging,max_iter=8,trace=1)\n",
    "utl.getTasa(classifier,datos_test_tokenizados_pos_tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"END: \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 11. Conclusiones\n",
    "\n",
    "En base a los resultados obtenidos, si bien estos son aceptables, creemos que podrían ser mejorados aún más. Según el análisis realizado sobre corpus este presenta una disparidad en la distribución de comentarios por cada clase, esto sumado a que el corpus es relativamente pequeño afectó mayoritariamente de forma negativa a la clasificación de los comentarios neutros.\n",
    "\n",
    "Evaluando la media de los resultados obtenidos en base a los distintos clasificadores creados, creemos que el clasificador elaborado se comporta satisfactoriamente, especialmente teniendo en cuenta que los seres humanos se ponen de acuerdo en la valoración en aproximadamente el 80% de los casos (http://sentdex.com/sentiment-analysis/), además teniendo en cuenta que un clasificador aleatorio obtendría un 33% de accuracy ya que la probabilidad de etiquetar un comentario correctamente es de un tercio.\n",
    "\n",
    "Por otro lado, el clasificador que obtuvo mejores resultados fue el que se entrenó con el corpus tokenizado con Freeling agregando información de POS-tagging e incorporando las palabras más frecuentes y los elementos subjetivos.\n",
    "\n",
    "#### Posibles mejoras\n",
    "\n",
    "Como mencionamos anteriormente hay algunos problemas que se podrían ver solucionados incorporando algunas mejoras.\n",
    "Por ejemplo en el corpus: \n",
    "\n",
    "- Contar con ejemplos que estén distribuidos homogéneamente para poder mejorar las clasificaciones de comentarios según su clase.\n",
    "- Contar con una lista de elementos subjetivos mejorada que esté más relacionada con el ámbito del cine.\n",
    "- Utilizar otro tipo de clasificador para realizar la clasificación de los comentarios y poder realizar un análisis comparativo de los mismos. Entre ellos se podrían utilizar Naive Bayes, Árboles de Decisión, entre otros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrantes\n",
    "\n",
    "- Federico Kauffman, 4.580.929-7\n",
    "- Martín Steglich, 4.607.084-9\n",
    "- Sergio Bonilla, 4.430.955-3\n",
    "- Martín Méndez, 5.163.637-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
