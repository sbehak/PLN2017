{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio de Introducción al Procesamiento de Lenguaje Natural 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de grupo: 13\n",
    "#### Integrantes:\n",
    "- Giovani Rondán, CI: 4.528.997-6\n",
    "- Santiago Behak, CI: 5.019.450-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Importación de los tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos importando los tweets provenientes del archivo \"corpus_humor_training.csv\" usando la librería Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import re\n",
    "#import freeling\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import IPython.display as disp\n",
    "import os\n",
    "\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los registros de este corpus están compuestos por varios datos además del propio texto del tweet. A continuación mostraremos la estructura del corpus y algunos de los tweets (que se encuentran en el atributo \"text\") a modo de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'text', 'account_id', 'n', '1', '2', '3', '4', '5'], dtype='object')\n",
      "\n",
      "\n",
      "-La semana pasada mi hijo hizo un triple salto mortal desde 20 metros de altura - ¿Es trapecista? -Era :(\n",
      "\n",
      "-Yo ya voy por mi segundo millón de dólares... -¿!Ah, si!? -Es que el primero nunca lo hice... #fb\n",
      "\n",
      "-Ayer fue mi cumpleaños y no me felicitaste - ¡FéÉLíCÍDáÁDÉéS! - ¿Qué haces? -Felicitarte con retraso.\n",
      "\n",
      "No es flojera, es un estado de ahorro de energía corporal :)\n",
      "\n",
      "- ¿Cómo te fue en matemática? -Vos sabes que soy muy pacífica - ¿Y eso qué tiene que ver? -No me gustan los problemas jajaja -Castigada - :(\n",
      "\n",
      "\"El pesimista se queja del viento; el optimista espera que cambie; el realista ajusta las velas\" Feliz miércoles.\n",
      "\n",
      "-¿Y tú desde cuando llevas pendiente? \r\n",
      "-Desde que mi mujer se lo encontró en el coche y le dije que era mío...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus.columns)\n",
    "print (\"\\n\")\n",
    "for text in corpus['text'][:7]:\n",
    "    print(text + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación porocedemos a analizar las características del corpus obtenido, para esto obtendremos algunos datos básicos tales como la cantidad total de tweets, la cantidad de atributos de los que disponemos, la cantidad de calificaciones de los 10 tweets más calificados y la cantidad total de calificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Tweets en el corpus: 12106\n",
      "Cantidad de atributos en el corpus: 9\n",
      "Lista de los diez tweets con más calificaciones:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>account_id</th>\n",
       "      <th>n</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>cantCalificaciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>445969156437852161</td>\n",
       "      <td>—¿A dónde vas tan maquillada? —A una fiesta, m...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>446273545304162304</td>\n",
       "      <td>JAJAJAJAJAJA ¿TE ACUERDAS CUANDO... ah, no, tú...</td>\n",
       "      <td>229144847</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>446423336831053824</td>\n",
       "      <td>\"Tu invades mi cabeza\" —Juanita, 10 años, tien...</td>\n",
       "      <td>229144847</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11728</th>\n",
       "      <td>464188098780618752</td>\n",
       "      <td>#Chistetipico</td>\n",
       "      <td>124053720</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849</th>\n",
       "      <td>447042317480763393</td>\n",
       "      <td>\"Es imposible\" dijo el orgullo; \"es arriesgado...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8966</th>\n",
       "      <td>448704341365366784</td>\n",
       "      <td>-Tenemos una relación seria. -¿Lleváis mucho t...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>446934186889211905</td>\n",
       "      <td>Hablo 3 idiomas: español, sarcasmos e indirectas.</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7037</th>\n",
       "      <td>445481775133777921</td>\n",
       "      <td>Molestar a alguien solo porque te gusta ver co...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>445669834211069952</td>\n",
       "      <td>A mi también me castigaron por reírme mientras...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>447613590992732160</td>\n",
       "      <td>—En mis tiempos... —Sí, sí abuela, como digas,...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "5879   445969156437852161  —¿A dónde vas tan maquillada? —A una fiesta, m...   \n",
       "8158   446273545304162304  JAJAJAJAJAJA ¿TE ACUERDAS CUANDO... ah, no, tú...   \n",
       "10238  446423336831053824  \"Tu invades mi cabeza\" —Juanita, 10 años, tien...   \n",
       "11728  464188098780618752                                     #Chistetipico    \n",
       "7849   447042317480763393  \"Es imposible\" dijo el orgullo; \"es arriesgado...   \n",
       "8966   448704341365366784  -Tenemos una relación seria. -¿Lleváis mucho t...   \n",
       "1117   446934186889211905  Hablo 3 idiomas: español, sarcasmos e indirectas.   \n",
       "7037   445481775133777921  Molestar a alguien solo porque te gusta ver co...   \n",
       "9273   445669834211069952  A mi también me castigaron por reírme mientras...   \n",
       "4306   447613590992732160  —En mis tiempos... —Sí, sí abuela, como digas,...   \n",
       "\n",
       "       account_id   n  1  2  3  4  5  cantCalificaciones  \n",
       "5879   1518218509   2  6  3  2  6  2                  21  \n",
       "8158    229144847  13  2  1  4  0  0                  20  \n",
       "10238   229144847   4  6  4  3  2  0                  19  \n",
       "11728   124053720  17  0  0  0  1  0                  18  \n",
       "7849   1518218509   6  6  1  1  3  0                  17  \n",
       "8966   1518218509   1  2  4  3  3  4                  17  \n",
       "1117   1518218509   6  4  1  4  0  1                  16  \n",
       "7037   1518218509  14  1  0  1  0  0                  16  \n",
       "9273   1518218509  11  3  0  0  2  0                  16  \n",
       "4306   1518218509   4  1  3  4  2  1                  15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cantTweets = len(corpus)\n",
    "cantAtributos = len(corpus.columns)\n",
    "\n",
    "# Imprimimos la cantidad total de tweets y la cantidad de atributos\n",
    "print (\"Cantidad de Tweets en el corpus: \" + str(cantTweets))\n",
    "print (\"Cantidad de atributos en el corpus: \" + str(cantAtributos))\n",
    "\n",
    "# Imprimimos la cantidad de calificaciones de los 10 tweets mas calificados y la cantidad total de calificaciones\n",
    "totalCalificaciones = 0\n",
    "contador = 0\n",
    "corpus[\"cantCalificaciones\"] = [0]*len(corpus)\n",
    "for i in range(0, 12106):\n",
    "    calificacionesTweet =corpus.loc[i, \"n\"] + corpus.loc[i, \"1\"]  + corpus.loc[i, \"2\"] + corpus.loc[i, \"3\"] + corpus.loc[i, \"4\"] + corpus.loc[i, \"5\"]\n",
    "    totalCalificaciones += calificacionesTweet\n",
    "    corpus.loc[i, \"cantCalificaciones\"] = calificacionesTweet\n",
    "\n",
    "print (\"Lista de los diez tweets con más calificaciones:\\n\")\n",
    "disp.display(corpus.sort_values(by = ['cantCalificaciones'], ascending = False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro dato que puede resultar interesante es la cantidad de calificaciones por valor (las calificaciones no humorísiticas serán contadas con el 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzErifwGLihAYRirG3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19566067d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Se realiza una gráfica de cantidad de comentarios en función de su clasificación\n",
    "calificacionesPorValor = [corpus[\"n\"].sum(), corpus[\"1\"].sum(), corpus[\"2\"].sum(), corpus[\"3\"].sum(), corpus[\"4\"].sum(), corpus[\"5\"].sum()]\n",
    "valoresCalificaciones = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "pos = arange(len(valoresCalificaciones)) + 0.5 \n",
    "\n",
    "figure(1)\n",
    "barh(pos,calificacionesPorValor, align='center')\n",
    "yticks(pos, valoresCalificaciones)\n",
    "xlabel('Cantidad de calificaciones')\n",
    "ylabel(u'Calificación')\n",
    "title(u'Cantidad de calificaciones por valor')\n",
    "grid(True)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la gráfica la mayoría de las calificaciones corresponden al valor 0, o sea, como calificaciones no humorísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Preprocesmiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En primer lugar procederemos a eleminar las columnas del corpus que consideramos innecesarias. Eliminaremos la columna de la id del tweet ya que este es un número autogenerado aleatorio que no debería aportar información relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'account_id', 'n', '1', '2', '3', '4', '5',\n",
      "       'cantCalificaciones'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if \"id\" in corpus.columns:\n",
    "    del corpus[\"id\"]\n",
    "print (corpus.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez filtradas las columnas del corpus nos disponemos a filtrar los tweets que tienen menos de tres calificaciones dado que los mismos no cuentan con una cantidad significativa de calificaciones como para ser evaluados. Además se eliminarán los hashtags de los textos de los tweets como se pide en la letra y agregaremos una nueva columna que determina si un tweet es humorístico en función del número de calificaciones no humorísticas en relación al total de calificaciones del tweet. Si la cantidad de calificaciones humorísticas es mayor o igual a la suma del resto de calificaciones el tweet se considerará no humorístico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>humoristico</th>\n",
       "      <th>cantCalificaciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-La semana pasada mi hijo hizo un triple salto...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Yo ya voy por mi segundo millón de dólares......</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Ayer fue mi cumpleaños y no me felicitaste - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No es flojera, es un estado de ahorro de energ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- ¿Cómo te fue en matemática? -Vos sabes que s...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-Compadre, su hija antes me daba como por las ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Había una vez una tortuguita que fue a su prim...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Una novia que sea tan delicada como Neymar, es...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>¿Qué le dice el Nesquik a la leche? ¡Te voy a ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Si oscar se queda me pego un tiro con un banan...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>- ¿Cual es tu nombre? -Pikachu Rodríguez, ¿y e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  n  1  2  3  4  5  \\\n",
       "0   -La semana pasada mi hijo hizo un triple salto...  0  1  1  0  0  1   \n",
       "1   -Yo ya voy por mi segundo millón de dólares......  2  1  0  0  0  0   \n",
       "2   -Ayer fue mi cumpleaños y no me felicitaste - ...  0  1  1  1  0  1   \n",
       "3   No es flojera, es un estado de ahorro de energ...  1  1  1  0  0  0   \n",
       "4   - ¿Cómo te fue en matemática? -Vos sabes que s...  2  0  0  1  0  0   \n",
       "5   -Compadre, su hija antes me daba como por las ...  1  1  0  0  1  0   \n",
       "6   Había una vez una tortuguita que fue a su prim...  1  2  1  0  0  0   \n",
       "7   Una novia que sea tan delicada como Neymar, es...  2  0  0  0  1  0   \n",
       "8   ¿Qué le dice el Nesquik a la leche? ¡Te voy a ...  2  1  0  0  1  0   \n",
       "9   Si oscar se queda me pego un tiro con un banan...  6  1  1  0  1  0   \n",
       "10  - ¿Cual es tu nombre? -Pikachu Rodríguez, ¿y e...  0  0  1  0  2  0   \n",
       "\n",
       "   humoristico cantCalificaciones  \n",
       "0         True                  3  \n",
       "1        False                  3  \n",
       "2         True                  4  \n",
       "3         True                  3  \n",
       "4        False                  3  \n",
       "5         True                  3  \n",
       "6         True                  4  \n",
       "7        False                  3  \n",
       "8         True                  4  \n",
       "9        False                  9  \n",
       "10        True                  3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets que quedan en el corpus luego del filtrado: 3438\n"
     ]
    }
   ],
   "source": [
    "corpus[\"humoristico\"] = [False]*len(corpus)\n",
    "corpus_filtrado = pandas.DataFrame(columns = ['text', 'n', '1', '2', '3', '4', '5', 'humoristico', 'cantCalificaciones'])\n",
    "#corpus_filtrado = corpus[corpus.n + corpus.columns[4] + corpus.columns[5] + corpus.columns[6] + corpus.columns[7] + corpus.columns[8] >= 3]\n",
    "total = 0\n",
    "for i in range(0, 12106):\n",
    "    contador = corpus.loc[i, \"cantCalificaciones\"]\n",
    "    #eliminamos los hashtags\n",
    "    corpus.loc[i, \"text\"] = re.sub(r\"#\\S+\\s*\", \"\", corpus.loc[i, \"text\"])\n",
    "    #definimos si un tweet es humoristico o no segun los votos\n",
    "    if(contador/2 >= corpus.loc[i, \"n\"]):\n",
    "        corpus.loc[i, \"humoristico\"] = True\n",
    "    #filtramos los tweets que tienen menos de 3 votos\n",
    "    if contador >= 3:\n",
    "        corpus_filtrado.loc[total] = [corpus.loc[i, \"text\"], corpus.loc[i, \"n\"], corpus.loc[i, \"1\"], corpus.loc[i, \"2\"], corpus.loc[i, \"3\"], corpus.loc[i, \"4\"], corpus.loc[i, \"5\"], corpus.loc[i, \"humoristico\"], corpus.loc[i, \"cantCalificaciones\"]]\n",
    "        total += 1\n",
    "        \n",
    "#columna 3 -> n, 4 -> 1, 5 -> 2, 6 -> 3, 7 -> 4, 8 -> 5\n",
    "\n",
    "disp.display(corpus_filtrado.loc[0:10, :])\n",
    "print (\"Cantidad de tweets que quedan en el corpus luego del filtrado: \" + str(len(corpus_filtrado)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Separación de los datos en conjunto de train y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación dividiremos el corpus restante en un conjunto de train y en otro de test. En principio usaremos un 80% de los datos para el entrenamiento y un 20% para el testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets en el conjunto de entrenamiento: 2750\n",
      "Cantidad de tweets en el conjunto de testeo: 688\n"
     ]
    }
   ],
   "source": [
    "corpus_train, corpus_test = train_test_split(corpus_filtrado, test_size=0.2)\n",
    "\n",
    "print (\"Cantidad de tweets en el conjunto de entrenamiento: \" + str(len(corpus_train)))\n",
    "print (\"Cantidad de tweets en el conjunto de testeo: \" + str(len(corpus_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Clasificador binario con tokenizador y POS tag de Freeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez separados el conjunto de train y test procedemos a tokenizar los tweets provenientes del conjunto train. Para esto usaremos la librería Freeling y NLTK. Primero definiremos una función que tokeniza un corpus usando freeling y a la que se le pueden pasar filtros para eliminar palabras basados en el postag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import datetime\n",
    "import traceback as tb\n",
    "\n",
    "def filtrar_corpus(corpus, largo_corpus, filtros, train, lemma = True, usuario = False):\n",
    "    result = []\n",
    "    palabras = \"\"\n",
    "    finTweet = \"13grupoPLN\"\n",
    "    cualquiera = 0\n",
    "    cualquiera2 = 0\n",
    "    for i in range(0,largo_corpus):\n",
    "        try:\n",
    "            palabras+= corpus.loc[i, \"text\"]\n",
    "            palabras+= \". \"\n",
    "            palabras+= finTweet\n",
    "            palabras+= \". \"\n",
    "            cualquiera += 1\n",
    "        except:\n",
    "            cualquiera2 += 1\n",
    "            pass\n",
    "\n",
    "    # Por cada palabra retornada de la tokenizacion del comentario\n",
    "    p = Popen(\"C:/Users/Usuario/Desktop/PLN2017/FreelingWindows/bin/analyzer.bat -f C:/Users/Usuario/Desktop/PLN2017/FreelingWindows/data/config/es.cfg\", shell = True, stdout=PIPE, stdin=PIPE, stderr=STDOUT)\n",
    "    stdout = p.communicate(input=palabras.encode())[0]\n",
    "    iterator = 0\n",
    "    tweets = stdout.decode().split('\\r\\n')\n",
    "    contador = 0\n",
    "    for palabra in tweets:\n",
    "        spliteado = palabra.split(' ')\n",
    "        if(spliteado[0] == finTweet):\n",
    "            contador += 1\n",
    "    for i in range(0,largo_corpus):\n",
    "        try:\n",
    "            esHumoristico = corpus.loc[i,\"humoristico\"]\n",
    "            error = False\n",
    "        except:\n",
    "            error = True\n",
    "        if (not error):\n",
    "            tokens = tweets[iterator].split(' ')\n",
    "            iterator += 1\n",
    "            diccionario = {}\n",
    "            while (tokens[0] != finTweet):\n",
    "                if(tokens[0] != ''):\n",
    "                    if(lemma):\n",
    "                        token = tokens[1]\n",
    "                    else:\n",
    "                        token = tokens[0]\n",
    "                    tag = tokens[2]\n",
    "                    flag = True\n",
    "                    for filtro in filtros:\n",
    "                        tag_aux = tag[0:len(filtro)]\n",
    "                        if (tag_aux == filtro):\n",
    "                            flag = False\n",
    "                            break\n",
    "                    if flag:\n",
    "                        if(token in diccionario):\n",
    "                            diccionario[token] = diccionario[token] + 1\n",
    "                        else:\n",
    "                            diccionario[token] = 1\n",
    "                tokens = tweets[iterator].split(' ')\n",
    "                iterator += 1\n",
    "            if(usuario):\n",
    "                diccionario[str(corpus.loc[i,\"account_id\"])] = 1\n",
    "            if(train):\n",
    "                result.append((diccionario,corpus.loc[i,\"humoristico\"]))\n",
    "            else:\n",
    "                result.append(diccionario)\n",
    "    return result\n",
    "\n",
    "#def agregar_tweet_diccionario(diccionario,tweet):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta función probaremos dos clasificadores (Naive Bayes y Máxima Entropía). Los filtros que consideramos usar son: \"F\" (signos de puntuacion), \"D\" (determinantes), \"P\" (pronombres), \"S\" (aposiciones) y \"Z\" (números). Además, en esta función vectorizamos los lemas de las palabras en lugar de su forma, de esta forma agrupamos palabras que en definitiva tienen el mismo significado. Probaremos usar todas las combinaciones de clasificadores y filtros y veremos cuales dan mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<124>130   . |\n",
      "1 | 194<240>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5290697674418605\n",
      "Matriz de confusión de Maxima Entropia con filtros: F\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<149>152   . |\n",
      "1 | 169<218>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5334302325581395\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: D\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<113>120   . |\n",
      "1 | 205<250>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5276162790697675\n",
      "Matriz de confusión de Maxima Entropia con filtros: D\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<154>156   . |\n",
      "1 | 164<214>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5348837209302325\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: P\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<113>119   . |\n",
      "1 | 205<251>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5290697674418605\n",
      "Matriz de confusión de Maxima Entropia con filtros: P\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<153>149   . |\n",
      "1 | 165<221>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5436046511627907\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<114>113   . |\n",
      "1 | 204<257>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5392441860465116\n",
      "Matriz de confusión de Maxima Entropia con filtros: S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<154>148   . |\n",
      "1 | 164<222>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5465116279069767\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<110>115   . |\n",
      "1 | 208<255>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5305232558139535\n",
      "Matriz de confusión de Maxima Entropia con filtros: Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<154>146   . |\n",
      "1 | 164<224>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5494186046511628\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-D\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<128>141   . |\n",
      "1 | 190<229>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5188953488372093\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-D\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<150>157   . |\n",
      "1 | 168<213>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5276162790697675\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-P\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<132>131   . |\n",
      "1 | 186<239>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5392441860465116\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-P\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<141>150   . |\n",
      "1 | 177<220>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5247093023255814\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<123>130   . |\n",
      "1 | 195<240>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5276162790697675\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<148>158   . |\n",
      "1 | 170<212>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5232558139534884\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<125>133   . |\n",
      "1 | 193<237>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5261627906976745\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<147>151   . |\n",
      "1 | 171<219>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5319767441860465\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: D-P\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<117>122   . |\n",
      "1 | 201<248>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5305232558139535\n",
      "Matriz de confusión de Maxima Entropia con filtros: D-P\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<155>152   . |\n",
      "1 | 163<218>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5421511627906976\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: D-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<115>117   . |\n",
      "1 | 203<253>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5348837209302325\n",
      "Matriz de confusión de Maxima Entropia con filtros: D-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<155>155   . |\n",
      "1 | 163<215>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5377906976744186\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: D-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<113>122   . |\n",
      "1 | 205<248>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5247093023255814\n",
      "Matriz de confusión de Maxima Entropia con filtros: D-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<157>157   . |\n",
      "1 | 161<213>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5377906976744186\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: P-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<116>119   . |\n",
      "1 | 202<251>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5334302325581395\n",
      "Matriz de confusión de Maxima Entropia con filtros: P-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<155>150   . |\n",
      "1 | 163<220>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5450581395348837\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: P-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<115>121   . |\n",
      "1 | 203<249>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5290697674418605\n",
      "Matriz de confusión de Maxima Entropia con filtros: P-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<155>152   . |\n",
      "1 | 163<218>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5421511627906976\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<115>114   . |\n",
      "1 | 203<256>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5392441860465116\n",
      "Matriz de confusión de Maxima Entropia con filtros: S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<155>150   . |\n",
      "1 | 163<220>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5450581395348837\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-D-P\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<135>140   . |\n",
      "1 | 183<230>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5305232558139535\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-D-P\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<144>160   . |\n",
      "1 | 174<210>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5145348837209303\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-D-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<129>140   . |\n",
      "1 | 189<230>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5218023255813954\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-D-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<153>162   . |\n",
      "1 | 165<208>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5247093023255814\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-D-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<129>146   . |\n",
      "1 | 189<224>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5130813953488372\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-D-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<151>158   . |\n",
      "1 | 167<212>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5276162790697675\n",
      "2750\n",
      "688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-P-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<131>132   . |\n",
      "1 | 187<238>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5363372093023255\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-P-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<145>153   . |\n",
      "1 | 173<217>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5261627906976745\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-P-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<132>135   . |\n",
      "1 | 186<235>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5334302325581395\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-P-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<139>155   . |\n",
      "1 | 179<215>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5145348837209303\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<127>133   . |\n",
      "1 | 191<237>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5290697674418605\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<148>156   . |\n",
      "1 | 170<214>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5261627906976745\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: D-P-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<118>123   . |\n",
      "1 | 200<247>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5305232558139535\n",
      "Matriz de confusión de Maxima Entropia con filtros: D-P-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<157>151   . |\n",
      "1 | 161<219>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5465116279069767\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: D-P-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<119>125   . |\n",
      "1 | 199<245>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5290697674418605\n",
      "Matriz de confusión de Maxima Entropia con filtros: D-P-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<156>152   . |\n",
      "1 | 162<218>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5436046511627907\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: D-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<116>120   . |\n",
      "1 | 202<250>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5319767441860465\n",
      "Matriz de confusión de Maxima Entropia con filtros: D-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<156>156   . |\n",
      "1 | 162<214>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5377906976744186\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: P-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<119>121   . |\n",
      "1 | 199<249>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5348837209302325\n",
      "Matriz de confusión de Maxima Entropia con filtros: P-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<156>153   . |\n",
      "1 | 162<217>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5421511627906976\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-D-P-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<133>140   . |\n",
      "1 | 185<230>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5276162790697675\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-D-P-S\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<147>156   . |\n",
      "1 | 171<214>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5247093023255814\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-D-P-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<135>143   . |\n",
      "1 | 183<227>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5261627906976745\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-D-P-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<145>156   . |\n",
      "1 | 173<214>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5218023255813954\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-D-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<131>144   . |\n",
      "1 | 187<226>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5188953488372093\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-D-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<154>161   . |\n",
      "1 | 164<209>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5276162790697675\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-P-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<133>136   . |\n",
      "1 | 185<234>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5334302325581395\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-P-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<145>154   . |\n",
      "1 | 173<216>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5247093023255814\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: D-P-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<121>126   . |\n",
      "1 | 197<244>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5305232558139535\n",
      "Matriz de confusión de Maxima Entropia con filtros: D-P-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<156>153   . |\n",
      "1 | 162<217>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5421511627906976\n",
      "2750\n",
      "688\n",
      "2750\n",
      "entrene\n",
      "688\n",
      "2750\n",
      "688\n",
      "Matriz de confusión de Naive Bayes con filtros: F-D-P-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<134>143   . |\n",
      "1 | 184<227>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5247093023255814\n",
      "Matriz de confusión de Maxima Entropia con filtros: F-D-P-S-Z\n",
      "  |   0   1   2 |\n",
      "--+-------------+\n",
      "0 |<147>158   . |\n",
      "1 | 171<212>  . |\n",
      "2 |   .   .  <.>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy: 0.5218023255813954\n",
      "Mejor combinacion: Z\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.metrics.scores import *\n",
    "import itertools\n",
    "\n",
    "max_accuracy = 0\n",
    "filtros = [\"F\", \"D\", \"P\", \"S\", \"Z\"]\n",
    "for i in range(1, len(filtros) + 1):\n",
    "    filter_combinations = itertools.combinations(filtros, i)\n",
    "    for filter_combination in filter_combinations:\n",
    "        corpus_pos_tagging = filtrar_corpus(corpus_train, len(corpus_filtrado), filter_combination, True)\n",
    "        classifiers = []\n",
    "        classifiers += [[nltk.classify.NaiveBayesClassifier.train(corpus_pos_tagging), \"Naive Bayes\"]]\n",
    "        classifiers += [[nltk.classify.MaxentClassifier.train(corpus_pos_tagging, max_iter=8,trace=0), \"Maxima Entropia\"]]\n",
    "\n",
    "        print(\"entrene\")\n",
    "        #for classifier in classifiers:\n",
    "        #    classifier[0].show_most_informative_features()\n",
    "        salida = []\n",
    "        corpus_test_tokenizado = filtrar_corpus(corpus_test, len(corpus_filtrado), filter_combination, False)\n",
    "        for classifier in classifiers:\n",
    "            salidaClasificador = []\n",
    "            for tweet in corpus_test_tokenizado:\n",
    "                # Se obtiene la clasificacion del algoritmo para el comentario\n",
    "                try:\n",
    "                    clasificacion = classifier[0].classify(tweet)\n",
    "                    salidaClasificador.append(clasificacion)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            salida = corpus_test.loc[:, \"humoristico\"]\n",
    "            cm = nltk.ConfusionMatrix(salidaClasificador, salida)\n",
    "            print(\"Matriz de confusión de \" + classifier[1] + \" con filtros: \" + '-'.join(filter_combination))\n",
    "            print(cm)\n",
    "            acc = accuracy(salidaClasificador, salida)\n",
    "            print(\"Accuracy: \" + str(acc))\n",
    "            if acc > max_accuracy:\n",
    "                max_accuracy = acc\n",
    "                best_combination = filter_combination\n",
    "                \n",
    "print(\"Mejor combinacion: \" + '-'.join(best_combination))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver los mejores resultados se dan con Maxima Entropia cuando solo se tiene el filtro \"Z\" de los números con 55% de precisión. De todas formas los resultados no son muy buenos y no parecen variar mucho en función de los filtros usados (todos los resultados varían en el entorno del 51% y 55% de precisión). En función de estos resultados mantendremos el clasificador de maxima entropia y el filtro para los números pero agregaremos más features para intentar mejorar los resultados.\n",
    "Una primera mejora que podemos hacer es registrar la forma de las palabras en lugar de su lema como estábamos haciendo hasta ahora. Estos son los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pos_tagging = filtrar_corpus(corpus_train, len(corpus_filtrado), [\"Z\"], True, True, False)\n",
    "clf = nltk.classify.MaxentClassifier.train(corpus_pos_tagging, max_iter=8,trace=0)\n",
    "corpus_test_tokenizado = filtrar_corpus(corpus_test, len(corpus_filtrado), [\"Z\"], False, True, False)\n",
    "salidaClasificador = []\n",
    "salida = []\n",
    "for tweet in corpus_test_tokenizado:\n",
    "    # Se obtiene la clasificacion del algoritmo para el comentario\n",
    "    try:\n",
    "        clasificacion = classifier[0].classify(tweet)\n",
    "        salidaClasificador.append(clasificacion)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "salida = corpus_test.loc[:, \"humoristico\"]\n",
    "cm = nltk.ConfusionMatrix(salidaClasificador, salida)\n",
    "print(\"Matriz de confusión de \" + classifier[1] + \" con filtros: Z\")\n",
    "print(cm)\n",
    "acc = accuracy(salidaClasificador, salida)\n",
    "print(\"Accuracy: \" + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1- Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
