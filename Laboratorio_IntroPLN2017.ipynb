{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio de Introducción al Procesamiento de Lenguaje Natural 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de grupo: 13\n",
    "#### Integrantes:\n",
    "- Giovani Rondán, CI: 4.528.997-6\n",
    "- Santiago Behak, CI: 5.019.450-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Importación de los tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos importando los tweets provenientes del archivo \"corpus_humor_training.csv\" usando la librería Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import csv\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import re\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import IPython.display as disp\n",
    "import os\n",
    "import statistics\n",
    "import math\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import datetime\n",
    "import traceback as tb\n",
    "import nltk\n",
    "from nltk.metrics.scores import *\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los registros de este corpus están compuestos por varios datos además del propio texto del tweet. A continuación mostraremos la estructura del corpus y algunos de los tweets (que se encuentran en el atributo \"text\") a modo de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'text', 'account_id', 'n', '1', '2', '3', '4', '5'], dtype='object')\n",
      "\n",
      "\n",
      "-La semana pasada mi hijo hizo un triple salto mortal desde 20 metros de altura - ¿Es trapecista? -Era :(\n",
      "\n",
      "-Yo ya voy por mi segundo millón de dólares... -¿!Ah, si!? -Es que el primero nunca lo hice... #fb\n",
      "\n",
      "-Ayer fue mi cumpleaños y no me felicitaste - ¡FéÉLíCÍDáÁDÉéS! - ¿Qué haces? -Felicitarte con retraso.\n",
      "\n",
      "No es flojera, es un estado de ahorro de energía corporal :)\n",
      "\n",
      "- ¿Cómo te fue en matemática? -Vos sabes que soy muy pacífica - ¿Y eso qué tiene que ver? -No me gustan los problemas jajaja -Castigada - :(\n",
      "\n",
      "\"El pesimista se queja del viento; el optimista espera que cambie; el realista ajusta las velas\" Feliz miércoles.\n",
      "\n",
      "-¿Y tú desde cuando llevas pendiente? \r\n",
      "-Desde que mi mujer se lo encontró en el coche y le dije que era mío...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus.columns)\n",
    "print (\"\\n\")\n",
    "for text in corpus['text'][:7]:\n",
    "    print(text + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación porocedemos a analizar las características del corpus obtenido, para esto obtendremos algunos datos básicos tales como la cantidad total de tweets, la cantidad de atributos de los que disponemos, la cantidad de calificaciones de los 10 tweets más calificados y la cantidad total de calificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Tweets en el corpus: 12106\n",
      "Cantidad de atributos en el corpus: 9\n",
      "Lista de los diez tweets con más calificaciones:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>account_id</th>\n",
       "      <th>n</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>cantCalificaciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>445969156437852161</td>\n",
       "      <td>—¿A dónde vas tan maquillada? —A una fiesta, m...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>446273545304162304</td>\n",
       "      <td>JAJAJAJAJAJA ¿TE ACUERDAS CUANDO... ah, no, tú...</td>\n",
       "      <td>229144847</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>446423336831053824</td>\n",
       "      <td>\"Tu invades mi cabeza\" —Juanita, 10 años, tien...</td>\n",
       "      <td>229144847</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11728</th>\n",
       "      <td>464188098780618752</td>\n",
       "      <td>#Chistetipico</td>\n",
       "      <td>124053720</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849</th>\n",
       "      <td>447042317480763393</td>\n",
       "      <td>\"Es imposible\" dijo el orgullo; \"es arriesgado...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8966</th>\n",
       "      <td>448704341365366784</td>\n",
       "      <td>-Tenemos una relación seria. -¿Lleváis mucho t...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>446934186889211905</td>\n",
       "      <td>Hablo 3 idiomas: español, sarcasmos e indirectas.</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7037</th>\n",
       "      <td>445481775133777921</td>\n",
       "      <td>Molestar a alguien solo porque te gusta ver co...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>445669834211069952</td>\n",
       "      <td>A mi también me castigaron por reírme mientras...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>447613590992732160</td>\n",
       "      <td>—En mis tiempos... —Sí, sí abuela, como digas,...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "5879   445969156437852161  —¿A dónde vas tan maquillada? —A una fiesta, m...   \n",
       "8158   446273545304162304  JAJAJAJAJAJA ¿TE ACUERDAS CUANDO... ah, no, tú...   \n",
       "10238  446423336831053824  \"Tu invades mi cabeza\" —Juanita, 10 años, tien...   \n",
       "11728  464188098780618752                                     #Chistetipico    \n",
       "7849   447042317480763393  \"Es imposible\" dijo el orgullo; \"es arriesgado...   \n",
       "8966   448704341365366784  -Tenemos una relación seria. -¿Lleváis mucho t...   \n",
       "1117   446934186889211905  Hablo 3 idiomas: español, sarcasmos e indirectas.   \n",
       "7037   445481775133777921  Molestar a alguien solo porque te gusta ver co...   \n",
       "9273   445669834211069952  A mi también me castigaron por reírme mientras...   \n",
       "4306   447613590992732160  —En mis tiempos... —Sí, sí abuela, como digas,...   \n",
       "\n",
       "       account_id   n  1  2  3  4  5  cantCalificaciones  \n",
       "5879   1518218509   2  6  3  2  6  2                  21  \n",
       "8158    229144847  13  2  1  4  0  0                  20  \n",
       "10238   229144847   4  6  4  3  2  0                  19  \n",
       "11728   124053720  17  0  0  0  1  0                  18  \n",
       "7849   1518218509   6  6  1  1  3  0                  17  \n",
       "8966   1518218509   1  2  4  3  3  4                  17  \n",
       "1117   1518218509   6  4  1  4  0  1                  16  \n",
       "7037   1518218509  14  1  0  1  0  0                  16  \n",
       "9273   1518218509  11  3  0  0  2  0                  16  \n",
       "4306   1518218509   4  1  3  4  2  1                  15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cantTweets = len(corpus)\n",
    "cantAtributos = len(corpus.columns)\n",
    "\n",
    "# Imprimimos la cantidad total de tweets y la cantidad de atributos\n",
    "print (\"Cantidad de Tweets en el corpus: \" + str(cantTweets))\n",
    "print (\"Cantidad de atributos en el corpus: \" + str(cantAtributos))\n",
    "\n",
    "# Imprimimos la cantidad de calificaciones de los 10 tweets mas calificados y la cantidad total de calificaciones\n",
    "totalCalificaciones = 0\n",
    "contador = 0\n",
    "corpus[\"cantCalificaciones\"] = [0]*len(corpus)\n",
    "for i in range(0, len(corpus)):\n",
    "    calificacionesTweet =corpus.loc[i, \"n\"] + corpus.loc[i, \"1\"]  + corpus.loc[i, \"2\"] + corpus.loc[i, \"3\"] + corpus.loc[i, \"4\"] + corpus.loc[i, \"5\"]\n",
    "    totalCalificaciones += calificacionesTweet\n",
    "    corpus.loc[i, \"cantCalificaciones\"] = calificacionesTweet\n",
    "\n",
    "print (\"Lista de los diez tweets con más calificaciones:\\n\")\n",
    "disp.display(corpus.sort_values(by = ['cantCalificaciones'], ascending = False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro dato que puede resultar interesante es la cantidad de calificaciones por valor (las calificaciones no humorísiticas serán contadas con el 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzErifwGLihAYRirG3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x273d1aed908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Se realiza una gráfica de cantidad de comentarios en función de su clasificación\n",
    "calificacionesPorValor = [corpus[\"n\"].sum(), corpus[\"1\"].sum(), corpus[\"2\"].sum(), corpus[\"3\"].sum(), corpus[\"4\"].sum(), corpus[\"5\"].sum()]\n",
    "valoresCalificaciones = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "pos = arange(len(valoresCalificaciones)) + 0.5 \n",
    "\n",
    "figure(1)\n",
    "barh(pos,calificacionesPorValor, align='center')\n",
    "yticks(pos, valoresCalificaciones)\n",
    "xlabel('Cantidad de calificaciones')\n",
    "ylabel(u'Calificación')\n",
    "title(u'Cantidad de calificaciones por valor')\n",
    "grid(True)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la gráfica la mayoría de las calificaciones corresponden al valor 0, o sea, como calificaciones no humorísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Preprocesmiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En primer lugar procederemos a eleminar las columnas del corpus que consideramos innecesarias. Eliminaremos la columna de la id del tweet ya que este es un número autogenerado aleatorio que no debería aportar información relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'account_id', 'n', '1', '2', '3', '4', '5',\n",
      "       'cantCalificaciones'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if \"id\" in corpus.columns:\n",
    "    del corpus[\"id\"]\n",
    "print (corpus.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez filtradas las columnas del corpus nos disponemos a filtrar los tweets que tienen menos de tres calificaciones dado que los mismos no cuentan con una cantidad significativa de calificaciones como para ser evaluados. Además se eliminarán los hashtags de los textos de los tweets y agregaremos una nueva columna que determina si un tweet es humorístico en función del número de calificaciones no humorísticas en relación al total de calificaciones del tweet. Si la cantidad de calificaciones humorísticas es mayor o igual a la suma del resto de calificaciones el tweet se considerará no humorístico. También calcularemos y agregaremos otra columna que contenga la mediana de las claificaciones de los tweets, donde las calificaciones no humorísticas contarán como 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>account_id</th>\n",
       "      <th>n</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>humoristico</th>\n",
       "      <th>cantCalificaciones</th>\n",
       "      <th>mediana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-La semana pasada mi hijo hizo un triple salto...</td>\n",
       "      <td>118161896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Yo ya voy por mi segundo millón de dólares......</td>\n",
       "      <td>132679073</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Ayer fue mi cumpleaños y no me felicitaste - ...</td>\n",
       "      <td>118161896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No es flojera, es un estado de ahorro de energ...</td>\n",
       "      <td>1518218509</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- ¿Cómo te fue en matemática? -Vos sabes que s...</td>\n",
       "      <td>118161896</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-Compadre, su hija antes me daba como por las ...</td>\n",
       "      <td>132679073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Había una vez una tortuguita que fue a su prim...</td>\n",
       "      <td>142482558</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Una novia que sea tan delicada como Neymar, es...</td>\n",
       "      <td>142482558</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>¿Qué le dice el Nesquik a la leche? ¡Te voy a ...</td>\n",
       "      <td>132679073</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Si oscar se queda me pego un tiro con un banan...</td>\n",
       "      <td>574848706</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>- ¿Cual es tu nombre? -Pikachu Rodríguez, ¿y e...</td>\n",
       "      <td>118161896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  account_id  n  1  2  3  \\\n",
       "0   -La semana pasada mi hijo hizo un triple salto...   118161896  0  1  1  0   \n",
       "1   -Yo ya voy por mi segundo millón de dólares......   132679073  2  1  0  0   \n",
       "2   -Ayer fue mi cumpleaños y no me felicitaste - ...   118161896  0  1  1  1   \n",
       "3   No es flojera, es un estado de ahorro de energ...  1518218509  1  1  1  0   \n",
       "4   - ¿Cómo te fue en matemática? -Vos sabes que s...   118161896  2  0  0  1   \n",
       "5   -Compadre, su hija antes me daba como por las ...   132679073  1  1  0  0   \n",
       "6   Había una vez una tortuguita que fue a su prim...   142482558  1  2  1  0   \n",
       "7   Una novia que sea tan delicada como Neymar, es...   142482558  2  0  0  0   \n",
       "8   ¿Qué le dice el Nesquik a la leche? ¡Te voy a ...   132679073  2  1  0  0   \n",
       "9   Si oscar se queda me pego un tiro con un banan...   574848706  6  1  1  0   \n",
       "10  - ¿Cual es tu nombre? -Pikachu Rodríguez, ¿y e...   118161896  0  0  1  0   \n",
       "\n",
       "    4  5 humoristico cantCalificaciones  mediana  \n",
       "0   0  1        True                  3      2.0  \n",
       "1   0  0       False                  3      0.0  \n",
       "2   0  1        True                  4      3.0  \n",
       "3   0  0        True                  3      1.0  \n",
       "4   0  0       False                  3      0.0  \n",
       "5   1  0        True                  3      1.0  \n",
       "6   0  0        True                  4      1.0  \n",
       "7   1  0       False                  3      0.0  \n",
       "8   1  0        True                  4      1.0  \n",
       "9   1  0       False                  9      0.0  \n",
       "10  2  0        True                  3      4.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets que quedan en el corpus luego del filtrado: 3438\n"
     ]
    }
   ],
   "source": [
    "corpus[\"humoristico\"] = [False]*len(corpus)\n",
    "corpus_filtrado = pandas.DataFrame(columns = ['text', 'account_id', 'n', '1', '2', '3', '4', '5', 'humoristico', 'cantCalificaciones', 'mediana'])\n",
    "#corpus_filtrado = corpus[corpus.n + corpus.columns[4] + corpus.columns[5] + corpus.columns[6] + corpus.columns[7] + corpus.columns[8] >= 3]\n",
    "total = 0\n",
    "for i in range(0, 12106):\n",
    "    contador = corpus.loc[i, \"cantCalificaciones\"]\n",
    "    #eliminamos los hashtags\n",
    "    corpus.loc[i, \"text\"] = re.sub(r\"#\\S+\\s*\", \"\", corpus.loc[i, \"text\"])\n",
    "    #definimos si un tweet es humoristico o no segun los votos\n",
    "    if(contador/2 >= corpus.loc[i, \"n\"]):\n",
    "        corpus.loc[i, \"humoristico\"] = True\n",
    "    #calculo mediana\n",
    "    califications= []\n",
    "    califications += [0]* corpus.loc[i, \"n\"]\n",
    "    califications += [1]* corpus.loc[i, \"1\"]\n",
    "    califications += [2]* corpus.loc[i, \"2\"]\n",
    "    califications += [3]* corpus.loc[i, \"3\"]\n",
    "    califications += [4]* corpus.loc[i, \"4\"]\n",
    "    califications += [5]* corpus.loc[i, \"5\"]\n",
    "    mediana = statistics.median(califications)\n",
    "    if (trunc(mediana) < mediana):\n",
    "        mediana = trunc(mediana) +1\n",
    "    corpus.loc[i,\"mediana\"] = mediana\n",
    "    #filtramos los tweets que tienen menos de 3 votos\n",
    "    if contador >= 3:\n",
    "        corpus_filtrado.loc[total] = [corpus.loc[i, \"text\"], corpus.loc[i, \"account_id\"], corpus.loc[i, \"n\"], corpus.loc[i, \"1\"], corpus.loc[i, \"2\"], corpus.loc[i, \"3\"], corpus.loc[i, \"4\"], corpus.loc[i, \"5\"], corpus.loc[i, \"humoristico\"], corpus.loc[i, \"cantCalificaciones\"],corpus.loc[i,\"mediana\"]]\n",
    "        total += 1\n",
    "        \n",
    "#columna 3 -> n, 4 -> 1, 5 -> 2, 6 -> 3, 7 -> 4, 8 -> 5\n",
    "print (\"Cantidad de tweets que quedan en el corpus luego del filtrado: \" + str(len(corpus_filtrado)))\n",
    "disp.display(corpus_filtrado.loc[0:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Separación de los datos en conjunto de train y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación dividiremos el corpus restante en un conjunto de train y en otro de test. En principio usaremos un 80% de los datos para el entrenamiento y un 20% para el testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tweets en el conjunto de entrenamiento: 2750\n",
      "Cantidad de tweets en el conjunto de testeo: 688\n"
     ]
    }
   ],
   "source": [
    "corpus_train, corpus_test = train_test_split(corpus_filtrado, test_size=0.2)\n",
    "\n",
    "print (\"Cantidad de tweets en el conjunto de entrenamiento: \" + str(len(corpus_train)))\n",
    "print (\"Cantidad de tweets en el conjunto de testeo: \" + str(len(corpus_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Clasificador binario con tokenizador y POS tag de Freeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1 Tokenización del corpus usando Freeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez separados el conjunto de train y test procedemos a tokenizar los tweets provenientes del conjunto train. Para esto usaremos la librería Freeling y NLTK. Primero definiremos una función que tokeniza un corpus usando freeling y a la que se le pueden pasar filtros para eliminar palabras basados en el postag de Freeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filtrar_corpus(corpus, filtros, train, lemma = False, usuario = False, with_tag = False, mediana = False):\n",
    "    result = []\n",
    "    palabras = \"\"\n",
    "    finTweetH = \"13grupoPLN\"\n",
    "    finTweetNH = \"13grupoIPLN\"\n",
    "    \n",
    "    for index, tweet in corpus.iterrows():\n",
    "        palabras+= tweet[\"text\"]\n",
    "        palabras+= \". \"\n",
    "        if(tweet[\"humoristico\"]):\n",
    "            palabras+= finTweetH\n",
    "        else:\n",
    "            palabras+= finTweetNH\n",
    "        palabras+= \". \"\n",
    "\n",
    "    p = Popen(\"C:/Users/Usuario/Desktop/PLN2017/FreelingWindows/bin/analyzer.bat -f C:/Users/Usuario/Desktop/PLN2017/FreelingWindows/data/config/es.cfg\", shell = True, stdout=PIPE, stdin=PIPE, stderr=STDOUT)\n",
    "    stdout = p.communicate(input=palabras.encode())[0]\n",
    "    iterator = -1\n",
    "    tweets = stdout.decode().split('\\r\\n')\n",
    "    for index, row in corpus.iterrows():\n",
    "        iterator += 1\n",
    "        tokens = tweets[iterator].split(' ')\n",
    "        diccionario = {}\n",
    "        while (tokens[0] != finTweetH and tokens[0] != finTweetNH):\n",
    "            if(tokens[0] != ''):\n",
    "                if(lemma):\n",
    "                    token = tokens[1]\n",
    "                else:\n",
    "                    token = tokens[0]\n",
    "                tag = tokens[2]\n",
    "                flag = True\n",
    "                for filtro in filtros:\n",
    "                    tag_aux = tag[0:len(filtro)]\n",
    "                    if (tag_aux == filtro):\n",
    "                        flag = False\n",
    "                        break\n",
    "                if flag:\n",
    "                    if(token in diccionario):\n",
    "                        diccionario[token] += 1\n",
    "                    else:\n",
    "                        diccionario[token] = 1\n",
    "                    if(with_tag):\n",
    "                        if(tag in diccionario):\n",
    "                            diccionario[tag] += 1\n",
    "                        else:\n",
    "                            diccionario[tag] = 1\n",
    "            tokens = tweets[iterator].split(' ')\n",
    "            iterator += 1\n",
    "        if(usuario):\n",
    "            diccionario[row[\"account_id\"]] = 1\n",
    "        if(train):\n",
    "            if(mediana):\n",
    "                result.append((diccionario, row[\"mediana\"]))\n",
    "            else:\n",
    "                result.append((diccionario, tokens[0] == finTweetH))\n",
    "        else:\n",
    "            result.append(diccionario)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2 Pruebas de clasificadores y filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta función probaremos dos clasificadores (Naive Bayes y Máxima Entropía) y un conjunto de filtros para eliminar tokens que en principio no parecen tan interesantes. Los filtros que consideramos probar son: \"F\" (signos de puntuacion), \"D\" (determinantes), \"P\" (pronombres), \"S\" (aposiciones) y \"Z\" (números). Probaremos usar todas las combinaciones de clasificadores y filtros y veremos cuales dan mejores resultados. Por ahora los únicos features que usaremos para la clasificación serán la forma de las palabras, luego agregaremos más features una vez obtenida la configuración ideal. (Atención, la siguiente cell demora mucho en ejecutarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de Naive Bayes con filtros: F\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.56      0.64       331\n",
      "       True       0.67      0.83      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7020348837209303\n",
      "Resultados de Maxima Entropia con filtros: F\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.61      0.67       331\n",
      "       True       0.69      0.80      0.74       357\n",
      "\n",
      "avg / total       0.71      0.71      0.71       688\n",
      "\n",
      "Accuracy general: 0.7078488372093024\n",
      "Resultados de Naive Bayes con filtros: D\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.60      0.68       331\n",
      "       True       0.70      0.85      0.77       357\n",
      "\n",
      "avg / total       0.74      0.73      0.73       688\n",
      "\n",
      "Accuracy general: 0.7311046511627907\n",
      "Resultados de Maxima Entropia con filtros: D\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.69      0.72       331\n",
      "       True       0.73      0.80      0.76       357\n",
      "\n",
      "avg / total       0.74      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7427325581395349\n",
      "Resultados de Naive Bayes con filtros: P\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.58      0.67       331\n",
      "       True       0.69      0.86      0.76       357\n",
      "\n",
      "avg / total       0.74      0.72      0.72       688\n",
      "\n",
      "Accuracy general: 0.7238372093023255\n",
      "Resultados de Maxima Entropia con filtros: P\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.68      0.72       331\n",
      "       True       0.73      0.80      0.76       357\n",
      "\n",
      "avg / total       0.75      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7441860465116279\n",
      "Resultados de Naive Bayes con filtros: S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.59      0.67       331\n",
      "       True       0.69      0.85      0.76       357\n",
      "\n",
      "avg / total       0.74      0.73      0.72       688\n",
      "\n",
      "Accuracy general: 0.7252906976744186\n",
      "Resultados de Maxima Entropia con filtros: S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.68      0.72       331\n",
      "       True       0.73      0.81      0.77       357\n",
      "\n",
      "avg / total       0.75      0.75      0.74       688\n",
      "\n",
      "Accuracy general: 0.7456395348837209\n",
      "Resultados de Naive Bayes con filtros: Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.59      0.68       331\n",
      "       True       0.69      0.85      0.77       357\n",
      "\n",
      "avg / total       0.74      0.73      0.72       688\n",
      "\n",
      "Accuracy general: 0.7281976744186046\n",
      "Resultados de Maxima Entropia con filtros: Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.69      0.72       331\n",
      "       True       0.73      0.80      0.77       357\n",
      "\n",
      "avg / total       0.75      0.75      0.74       688\n",
      "\n",
      "Accuracy general: 0.7456395348837209\n",
      "Resultados de Naive Bayes con filtros: F-D\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.57      0.65       331\n",
      "       True       0.68      0.83      0.75       357\n",
      "\n",
      "avg / total       0.72      0.71      0.70       688\n",
      "\n",
      "Accuracy general: 0.7078488372093024\n",
      "Resultados de Maxima Entropia con filtros: F-D\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.64      0.68       331\n",
      "       True       0.70      0.79      0.74       357\n",
      "\n",
      "avg / total       0.72      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7151162790697675\n",
      "Resultados de Naive Bayes con filtros: F-P\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.56      0.65       331\n",
      "       True       0.67      0.85      0.75       357\n",
      "\n",
      "avg / total       0.72      0.71      0.70       688\n",
      "\n",
      "Accuracy general: 0.7063953488372093\n",
      "Resultados de Maxima Entropia con filtros: F-P\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.58      0.65       331\n",
      "       True       0.68      0.82      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7020348837209303\n",
      "Resultados de Naive Bayes con filtros: F-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.57      0.65       331\n",
      "       True       0.68      0.83      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7034883720930233\n",
      "Resultados de Maxima Entropia con filtros: F-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.73      0.62      0.67       331\n",
      "       True       0.69      0.79      0.74       357\n",
      "\n",
      "avg / total       0.71      0.71      0.71       688\n",
      "\n",
      "Accuracy general: 0.7078488372093024\n",
      "Resultados de Naive Bayes con filtros: F-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.57      0.65       331\n",
      "       True       0.67      0.83      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7034883720930233\n",
      "Resultados de Maxima Entropia con filtros: F-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.73      0.63      0.68       331\n",
      "       True       0.70      0.79      0.74       357\n",
      "\n",
      "avg / total       0.71      0.71      0.71       688\n",
      "\n",
      "Accuracy general: 0.7122093023255814\n",
      "Resultados de Naive Bayes con filtros: D-P\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.58      0.67       331\n",
      "       True       0.69      0.85      0.76       357\n",
      "\n",
      "avg / total       0.73      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7209302325581395\n",
      "Resultados de Maxima Entropia con filtros: D-P\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.66      0.70       331\n",
      "       True       0.72      0.80      0.75       357\n",
      "\n",
      "avg / total       0.73      0.73      0.73       688\n",
      "\n",
      "Accuracy general: 0.7311046511627907\n",
      "Resultados de Naive Bayes con filtros: D-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.60      0.68       331\n",
      "       True       0.70      0.84      0.76       357\n",
      "\n",
      "avg / total       0.74      0.73      0.72       688\n",
      "\n",
      "Accuracy general: 0.7281976744186046\n",
      "Resultados de Maxima Entropia con filtros: D-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.69      0.72       331\n",
      "       True       0.73      0.80      0.77       357\n",
      "\n",
      "avg / total       0.75      0.75      0.74       688\n",
      "\n",
      "Accuracy general: 0.7456395348837209\n",
      "Resultados de Naive Bayes con filtros: D-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.60      0.68       331\n",
      "       True       0.70      0.85      0.77       357\n",
      "\n",
      "avg / total       0.74      0.73      0.72       688\n",
      "\n",
      "Accuracy general: 0.7296511627906976\n",
      "Resultados de Maxima Entropia con filtros: D-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.69      0.72       331\n",
      "       True       0.74      0.79      0.76       357\n",
      "\n",
      "avg / total       0.74      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7427325581395349\n",
      "Resultados de Naive Bayes con filtros: P-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.57      0.66       331\n",
      "       True       0.68      0.85      0.76       357\n",
      "\n",
      "avg / total       0.73      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7165697674418605\n",
      "Resultados de Maxima Entropia con filtros: P-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.66      0.71       331\n",
      "       True       0.72      0.80      0.76       357\n",
      "\n",
      "avg / total       0.74      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7369186046511628\n",
      "Resultados de Naive Bayes con filtros: P-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.58      0.67       331\n",
      "       True       0.69      0.86      0.76       357\n",
      "\n",
      "avg / total       0.74      0.73      0.72       688\n",
      "\n",
      "Accuracy general: 0.7252906976744186\n",
      "Resultados de Maxima Entropia con filtros: P-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.69      0.72       331\n",
      "       True       0.73      0.80      0.76       357\n",
      "\n",
      "avg / total       0.75      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7441860465116279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de Naive Bayes con filtros: S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.59      0.67       331\n",
      "       True       0.69      0.85      0.76       357\n",
      "\n",
      "avg / total       0.73      0.72      0.72       688\n",
      "\n",
      "Accuracy general: 0.7223837209302325\n",
      "Resultados de Maxima Entropia con filtros: S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.69      0.72       331\n",
      "       True       0.73      0.80      0.77       357\n",
      "\n",
      "avg / total       0.75      0.75      0.74       688\n",
      "\n",
      "Accuracy general: 0.7456395348837209\n",
      "Resultados de Naive Bayes con filtros: F-D-P\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.56      0.65       331\n",
      "       True       0.67      0.83      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7034883720930233\n",
      "Resultados de Maxima Entropia con filtros: F-D-P\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.73      0.59      0.65       331\n",
      "       True       0.68      0.80      0.73       357\n",
      "\n",
      "avg / total       0.70      0.70      0.69       688\n",
      "\n",
      "Accuracy general: 0.6976744186046512\n",
      "Resultados de Naive Bayes con filtros: F-D-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.59      0.66       331\n",
      "       True       0.68      0.82      0.74       357\n",
      "\n",
      "avg / total       0.71      0.71      0.70       688\n",
      "\n",
      "Accuracy general: 0.7078488372093024\n",
      "Resultados de Maxima Entropia con filtros: F-D-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.73      0.64      0.68       331\n",
      "       True       0.70      0.78      0.74       357\n",
      "\n",
      "avg / total       0.72      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7151162790697675\n",
      "Resultados de Naive Bayes con filtros: F-D-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.58      0.66       331\n",
      "       True       0.68      0.82      0.74       357\n",
      "\n",
      "avg / total       0.71      0.71      0.70       688\n",
      "\n",
      "Accuracy general: 0.7063953488372093\n",
      "Resultados de Maxima Entropia con filtros: F-D-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.73      0.65      0.69       331\n",
      "       True       0.70      0.78      0.74       357\n",
      "\n",
      "avg / total       0.72      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7151162790697675\n",
      "Resultados de Naive Bayes con filtros: F-P-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.56      0.65       331\n",
      "       True       0.67      0.84      0.75       357\n",
      "\n",
      "avg / total       0.72      0.71      0.70       688\n",
      "\n",
      "Accuracy general: 0.7078488372093024\n",
      "Resultados de Maxima Entropia con filtros: F-P-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.58      0.65       331\n",
      "       True       0.68      0.81      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7020348837209303\n",
      "Resultados de Naive Bayes con filtros: F-P-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.56      0.65       331\n",
      "       True       0.68      0.84      0.75       357\n",
      "\n",
      "avg / total       0.72      0.71      0.70       688\n",
      "\n",
      "Accuracy general: 0.7078488372093024\n",
      "Resultados de Maxima Entropia con filtros: F-P-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.60      0.66       331\n",
      "       True       0.68      0.80      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7034883720930233\n",
      "Resultados de Naive Bayes con filtros: F-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.58      0.65       331\n",
      "       True       0.68      0.82      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7049418604651163\n",
      "Resultados de Maxima Entropia con filtros: F-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.73      0.63      0.68       331\n",
      "       True       0.70      0.78      0.74       357\n",
      "\n",
      "avg / total       0.71      0.71      0.71       688\n",
      "\n",
      "Accuracy general: 0.7122093023255814\n",
      "Resultados de Naive Bayes con filtros: D-P-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.59      0.67       331\n",
      "       True       0.69      0.84      0.76       357\n",
      "\n",
      "avg / total       0.73      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7194767441860465\n",
      "Resultados de Maxima Entropia con filtros: D-P-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.65      0.70       331\n",
      "       True       0.71      0.80      0.75       357\n",
      "\n",
      "avg / total       0.73      0.73      0.73       688\n",
      "\n",
      "Accuracy general: 0.7281976744186046\n",
      "Resultados de Naive Bayes con filtros: D-P-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.58      0.66       331\n",
      "       True       0.68      0.85      0.76       357\n",
      "\n",
      "avg / total       0.73      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7194767441860465\n",
      "Resultados de Maxima Entropia con filtros: D-P-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.68      0.71       331\n",
      "       True       0.73      0.79      0.76       357\n",
      "\n",
      "avg / total       0.74      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7383720930232558\n",
      "Resultados de Naive Bayes con filtros: D-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.61      0.68       331\n",
      "       True       0.70      0.84      0.76       357\n",
      "\n",
      "avg / total       0.74      0.73      0.73       688\n",
      "\n",
      "Accuracy general: 0.7296511627906976\n",
      "Resultados de Maxima Entropia con filtros: D-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.70      0.73       331\n",
      "       True       0.74      0.79      0.77       357\n",
      "\n",
      "avg / total       0.75      0.75      0.75       688\n",
      "\n",
      "Accuracy general: 0.748546511627907\n",
      "Resultados de Naive Bayes con filtros: P-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.58      0.67       331\n",
      "       True       0.69      0.85      0.76       357\n",
      "\n",
      "avg / total       0.73      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7194767441860465\n",
      "Resultados de Maxima Entropia con filtros: P-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.68      0.71       331\n",
      "       True       0.73      0.80      0.76       357\n",
      "\n",
      "avg / total       0.74      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7383720930232558\n",
      "Resultados de Naive Bayes con filtros: F-D-P-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.58      0.65       331\n",
      "       True       0.68      0.82      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7020348837209303\n",
      "Resultados de Maxima Entropia con filtros: F-D-P-S\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.72      0.59      0.65       331\n",
      "       True       0.68      0.79      0.73       357\n",
      "\n",
      "avg / total       0.70      0.69      0.69       688\n",
      "\n",
      "Accuracy general: 0.6947674418604651\n",
      "Resultados de Naive Bayes con filtros: F-D-P-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.57      0.65       331\n",
      "       True       0.67      0.82      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7020348837209303\n",
      "Resultados de Maxima Entropia con filtros: F-D-P-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.72      0.59      0.65       331\n",
      "       True       0.68      0.79      0.73       357\n",
      "\n",
      "avg / total       0.70      0.69      0.69       688\n",
      "\n",
      "Accuracy general: 0.6933139534883721\n",
      "Resultados de Naive Bayes con filtros: F-D-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.60      0.66       331\n",
      "       True       0.69      0.81      0.74       357\n",
      "\n",
      "avg / total       0.72      0.71      0.71       688\n",
      "\n",
      "Accuracy general: 0.7093023255813954\n",
      "Resultados de Maxima Entropia con filtros: F-D-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.73      0.65      0.69       331\n",
      "       True       0.71      0.77      0.74       357\n",
      "\n",
      "avg / total       0.72      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7151162790697675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de Naive Bayes con filtros: F-P-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.57      0.65       331\n",
      "       True       0.68      0.83      0.75       357\n",
      "\n",
      "avg / total       0.72      0.71      0.70       688\n",
      "\n",
      "Accuracy general: 0.7063953488372093\n",
      "Resultados de Maxima Entropia con filtros: F-P-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.60      0.66       331\n",
      "       True       0.68      0.80      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7034883720930233\n",
      "Resultados de Naive Bayes con filtros: D-P-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.59      0.67       331\n",
      "       True       0.69      0.84      0.76       357\n",
      "\n",
      "avg / total       0.73      0.72      0.71       688\n",
      "\n",
      "Accuracy general: 0.7194767441860465\n",
      "Resultados de Maxima Entropia con filtros: D-P-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.67      0.71       331\n",
      "       True       0.72      0.80      0.76       357\n",
      "\n",
      "avg / total       0.74      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7369186046511628\n",
      "Resultados de Naive Bayes con filtros: F-D-P-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.59      0.66       331\n",
      "       True       0.68      0.82      0.74       357\n",
      "\n",
      "avg / total       0.71      0.70      0.70       688\n",
      "\n",
      "Accuracy general: 0.7049418604651163\n",
      "Resultados de Maxima Entropia con filtros: F-D-P-S-Z\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.72      0.60      0.65       331\n",
      "       True       0.68      0.78      0.73       357\n",
      "\n",
      "avg / total       0.70      0.69      0.69       688\n",
      "\n",
      "Accuracy general: 0.6933139534883721\n",
      "\n",
      " Mejor combinacion: D-S-Z\n",
      " Mejor accuracy: 0.748546511627907\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = 0\n",
    "filtros = [\"F\", \"D\", \"P\", \"S\", \"Z\"]\n",
    "for i in range(1, len(filtros) + 1):\n",
    "    filter_combinations = itertools.combinations(filtros, i)\n",
    "    for filter_combination in filter_combinations:\n",
    "        corpus_pos_tagging = filtrar_corpus(corpus_train, filter_combination, True)\n",
    "        classifiers = []\n",
    "        classifiers += [[nltk.classify.NaiveBayesClassifier.train(corpus_pos_tagging), \"Naive Bayes\"]]\n",
    "        classifiers += [[nltk.classify.MaxentClassifier.train(corpus_pos_tagging, max_iter=8,trace=0), \"Maxima Entropia\"]]\n",
    "        #for classifier in classifiers:\n",
    "        #    classifier[0].show_most_informative_features()\n",
    "        clasificacionOficial = []\n",
    "        corpus_test_tokenizado = filtrar_corpus(corpus_test, filter_combination, False)\n",
    "        for classifier in classifiers:\n",
    "            clasificacionCLF = []\n",
    "            for tweet in corpus_test_tokenizado:\n",
    "                # Se obtiene la clasificacion del algoritmo para el comentario\n",
    "                try:\n",
    "                    clasificacion = classifier[0].classify(tweet)\n",
    "                    clasificacionCLF.append(clasificacion)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            clasificacionOficial = []\n",
    "            for index, a in corpus_test.iterrows():\n",
    "                clasificacionOficial.append(a[\"humoristico\"])\n",
    "\n",
    "            print(\"Resultados de \" + classifier[1] + \" con filtros: \" + '-'.join(filter_combination))\n",
    "            print(classification_report(clasificacionOficial, clasificacionCLF))\n",
    "            acc = accuracy(clasificacionOficial, clasificacionCLF)\n",
    "            print(\"Accuracy general: \" + str(acc))\n",
    "            if acc > max_accuracy:\n",
    "                max_accuracy = acc\n",
    "                best_combination = filter_combination\n",
    "                \n",
    "print(\"\\n Mejor combinacion: \" + '-'.join(best_combination) + \"\\n Mejor accuracy: \" + str(max_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de varias ejecuciones con diferentes conjuntos de test comprobamos que Máxima Entropía es claramente mejor que Naive Bayes para este clasificador: en todos los casos probados Máxima Entropía obtiene entre 2 y 5 puntos más de precisión que Naive Bayes. Además se puede ver que existen variaciones significativas de precisión para los diferentes filtros (en general existe una diferencia de 8 puntos entre la mejor y la peor combinación), en particular la precisión baja de forma apreciable en las combinaciones que poseen el filtro \"F\" (correspondiente a los signos de puntuación). De hecho si se listan los features más significativos de Naive Bayes sin aplicar ningún filtro se puede ver que algunos signos de puntuación como el guión \"-\" son de los tokens que aportan más información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       - = 4                True : False  =     18.3 : 1.0\n",
      "                BUEN_DIA = 1               False : True   =     16.7 : 1.0\n",
      "                      RT = 1               False : True   =     13.8 : 1.0\n",
      "                  Doctor = 1                True : False  =     12.9 : 1.0\n",
      "                    otro = 1                True : False  =     12.3 : 1.0\n",
      "                      RT = 2               False : True   =     12.1 : 1.0\n",
      "                    hijo = 1                True : False  =     11.5 : 1.0\n",
      "                   novio = 1                True : False  =     11.2 : 1.0\n",
      "                  JAJAJA = 1                True : False  =     11.2 : 1.0\n",
      "                    Hijo = 1                True : False  =     10.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "corpus_pos_tagging = filtrar_corpus(corpus_train, [], True)\n",
    "classifier = nltk.classify.NaiveBayesClassifier.train(corpus_pos_tagging)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probablemente esto se debe a que el guión se usa para simular diálogos, los cuáles son muy frecuentes en los chistes y los relatos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3 Pruebas con nuevos features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prueba anterior nos permite obtener entre un 72% y un 75% de precisión, así que intentaremos mejorar estos resultados agregando nuevos features como pueden ser la id del usuario, usar el lema de las palabras en lugar de su forma y el pos-tag devuelto por Freeling para los tokens. Para estas pruebas mantendremos el clasificador de Máxima Entropía además de todos los filtros menos el de los signos de puntuación porque, como ya discutimos, esta fue la combinación que dio mejores resultados en las pruebas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la prueba con features: False-False-False\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.67      0.71       331\n",
      "       True       0.72      0.80      0.76       357\n",
      "\n",
      "avg / total       0.74      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7369186046511628\n",
      "Resultados de la prueba con features: True-False-False\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.70      0.73       331\n",
      "       True       0.74      0.78      0.76       357\n",
      "\n",
      "avg / total       0.75      0.75      0.75       688\n",
      "\n",
      "Accuracy general: 0.7456395348837209\n",
      "Resultados de la prueba con features: False-True-False\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.71      0.73       331\n",
      "       True       0.75      0.79      0.77       357\n",
      "\n",
      "avg / total       0.75      0.75      0.75       688\n",
      "\n",
      "Accuracy general: 0.751453488372093\n",
      "Resultados de la prueba con features: True-True-False\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.72      0.74       331\n",
      "       True       0.75      0.79      0.77       357\n",
      "\n",
      "avg / total       0.76      0.76      0.76       688\n",
      "\n",
      "Accuracy general: 0.7558139534883721\n",
      "Resultados de la prueba con features: False-False-True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.70      0.72       331\n",
      "       True       0.74      0.78      0.76       357\n",
      "\n",
      "avg / total       0.74      0.74      0.74       688\n",
      "\n",
      "Accuracy general: 0.7441860465116279\n",
      "Resultados de la prueba con features: True-False-True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.72      0.74       331\n",
      "       True       0.75      0.78      0.77       357\n",
      "\n",
      "avg / total       0.75      0.75      0.75       688\n",
      "\n",
      "Accuracy general: 0.7543604651162791\n",
      "Resultados de la prueba con features: False-True-True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.72      0.74       331\n",
      "       True       0.75      0.78      0.77       357\n",
      "\n",
      "avg / total       0.75      0.75      0.75       688\n",
      "\n",
      "Accuracy general: 0.752906976744186\n",
      "Resultados de la prueba con features: True-True-True\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.74      0.75       331\n",
      "       True       0.76      0.79      0.78       357\n",
      "\n",
      "avg / total       0.76      0.76      0.76       688\n",
      "\n",
      "Accuracy general: 0.7630813953488372\n",
      "Mejor combinacion de features: True-True-True\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "\n",
    "for i in range(0, 8):\n",
    "    aux_i = i\n",
    "    bool1 = (1 == (aux_i % 2))\n",
    "    aux_i = aux_i // 2\n",
    "    bool2 = (1 == (aux_i % 2))\n",
    "    aux_i = aux_i // 2\n",
    "    bool3 = (1 == (aux_i % 2))\n",
    "    corpus_pos_tagging = filtrar_corpus(corpus_train, [\"P\", \"S\", \"Z\", \"D\"], True, bool1, bool2, bool3)\n",
    "    clf = nltk.classify.MaxentClassifier.train(corpus_pos_tagging, max_iter=8,trace=0)\n",
    "    corpus_test_tokenizado = filtrar_corpus(corpus_test, [\"P\", \"S\", \"Z\", \"D\"], False, bool1, bool2, bool3)\n",
    "    clasificacionCLF = []\n",
    "    clasificacionOficial = []\n",
    "    for tweet in corpus_test_tokenizado:\n",
    "        #Clasificamos los tweets del corpus de test\n",
    "        clasificacion = clf.classify(tweet)\n",
    "        clasificacionCLF.append(clasificacion)\n",
    "\n",
    "    #Obtenemos las clasificaciones oficiales de los tweets del conjunto de test para compararlos con los del clasificador\n",
    "    clasificacionOficial =[]\n",
    "    for index, a in corpus_test.iterrows():\n",
    "        clasificacionOficial.append(a[\"humoristico\"])\n",
    "    print(\"Resultados de la prueba con features: \" + str(bool1) + \"-\" + str(bool2) + \"-\" + str(bool3))\n",
    "    print(classification_report(clasificacionOficial, clasificacionCLF))\n",
    "    acc = accuracy(clasificacionCLF, clasificacionOficial)\n",
    "    print(\"Accuracy general: \" + str(acc))\n",
    "    \n",
    "    if(acc > best_accuracy):\n",
    "        best_accuracy = acc\n",
    "        best_features = [bool1, bool2, bool3]\n",
    "\n",
    "print(\"Mejor combinacion de features: \" + str(best_features[0]) + \"-\" + str(best_features[1]) + \"-\" + str(best_features[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las pruebas indican que los mejores resultados se obtienen cuando todas las features mencionadas (usuario, lema de la palabra, y pos-tags de Freeling) están presentes. En general se obtiene una mejora de entre de 2 y 5 puntos con respecto a la prueba anterior y de esta forma alcanzamos entre un 74% y un 79% de precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Clasificador por mediana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación construiremos un nuevo clasificador que evalúe la mediana de las clasificaciones de los tweets del corpus. Para esto usaremos la columna con los valores de las medianas previamente calculada y para ahorrar tiempo mantendremos la configuración paramétrica usada en la parte anterior (tipo de clasificador, filtros y features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados obtenidos para la prueba: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.63      0.94      0.76       331\n",
      "        1.0       0.25      0.13      0.17        99\n",
      "        2.0       0.23      0.13      0.17        98\n",
      "        3.0       0.30      0.23      0.26        96\n",
      "        4.0       0.19      0.06      0.09        52\n",
      "        5.0       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.43      0.52      0.46       688\n",
      "\n",
      "Accuracy general: 0.524709302326\n"
     ]
    }
   ],
   "source": [
    "corpus_pos_tagging = filtrar_corpus(corpus_train, [\"P\", \"S\", \"Z\",\"D\"], True, True, True, True,True)\n",
    "clf = nltk.classify.MaxentClassifier.train(corpus_pos_tagging, max_iter=8,trace=0)\n",
    "corpus_test_tokenizado = filtrar_corpus(corpus_test, [\"P\", \"S\", \"Z\",\"D\"], False, True, True, True)\n",
    "clasificacionCLFMediana = []\n",
    "clasificacionOficialMediana = []\n",
    "cont = 0\n",
    "for tweet in corpus_test_tokenizado:\n",
    "    # Se obtiene la clasificacion del algoritmo para el comentario\n",
    "    clasificacion = clf.classify(tweet)\n",
    "    clasificacionCLFMediana.append(clasificacion)\n",
    "clasificacionOficialMediana = corpus_test.loc[:, \"mediana\"]\n",
    "print(\"Resultados obtenidos para la prueba: \")\n",
    "acc = accuracy(clasificacionOficialMediana, clasificacionCLFMediana)\n",
    "print(classification_report(clasificacionOficialMediana, clasificacionCLFMediana))\n",
    "print(\"Accuracy general: \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de realizar varias pruebas podemos concluir que para este clasificador tenemos una precisión de entre un 48% y un 53%. Estos resultados son considerablemente más bajos que los del clasificador anterior pero si consideramos que este clasificador tiene seis valores posibles en vez de dos podemos decir que siguen siendo bastante buenos. Para ilustrar estos resultados podemos ver la matriz de confusión de la prueba y calcularemos el promedio y la varianza de la desviación de los mismos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion de la prueba: \n",
      "    |   0   1   2   3   4   5   6   7   8   9 |\n",
      "    |   .   .   .   .   .   .   .   .   .   . |\n",
      "    |   0   0   0   0   0   0   0   0   0   0 |\n",
      "----+-----------------------------------------+\n",
      "0.0 |<310>  6   8   5   1   1   .   .   .   . |\n",
      "1.0 |  56 <13> 15  12   3   .   .   .   .   . |\n",
      "2.0 |  46  14 <13> 20   5   .   .   .   .   . |\n",
      "3.0 |  50   9  12 <22>  3   .   .   .   .   . |\n",
      "4.0 |  24   9   7   9  <3>  .   .   .   .   . |\n",
      "5.0 |   4   1   1   5   1  <.>  .   .   .   . |\n",
      "6.0 |   .   .   .   .   .   .  <.>  .   .   . |\n",
      "7.0 |   .   .   .   .   .   .   .  <.>  .   . |\n",
      "8.0 |   .   .   .   .   .   .   .   .  <.>  . |\n",
      "9.0 |   .   .   .   .   .   .   .   .   .  <.>|\n",
      "----+-----------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Desviacion promedio de los resultados: 0.9491279069767442\n",
      "Varianza de la desviacion de los resultados: 1.5075864487560984\n"
     ]
    }
   ],
   "source": [
    "promedio_desviacion = 0\n",
    "varianza_desviacion = 0\n",
    "aux_clasificaciones = []\n",
    "for index, i in corpus_test.iterrows():\n",
    "    aux_clasificaciones.append(i[\"mediana\"]) \n",
    "\n",
    "for j in range(0, len(aux_clasificaciones)):\n",
    "    promedio_desviacion += abs(aux_clasificaciones[j] - clasificacionCLFMediana[j])\n",
    "promedio_desviacion = promedio_desviacion / len(clasificacionOficialMediana)\n",
    "\n",
    "for k in range(0, len(aux_clasificaciones)):\n",
    "    varianza_desviacion += (abs(aux_clasificaciones[k] - clasificacionCLFMediana[k]) - promedio_desviacion)**2\n",
    "varianza_desviacion = varianza_desviacion / len(clasificacionOficialMediana)\n",
    "print(\"Matriz de confusion de la prueba: \")\n",
    "print(nltk.ConfusionMatrix(clasificacionOficialMediana, clasificacionCLFMediana))\n",
    "\n",
    "print(\"Desviacion promedio de los resultados: \" + str(promedio_desviacion))\n",
    "print(\"Varianza de la desviacion de los resultados: \" + str(varianza_desviacion))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general obtenemos un promedio en la desviación de 0,95 y una varianza de 1,5. Esto indica que si bien tenemos una precisión relativamente baja en general el error en la estimación no es muy elevado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Clasificador binario basado en el clasificador por mediana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos el clasificador por mediana, buscamos crear un nuevo clasificador que determine si un tweet es humorístico o no basandonos en este. Para esto haremos un post-procesamiento de la clasificación arrojada por el clasificador por mediana para el conjunto de test en el que definiremos que un tweet humorístico es todo aquel que tenga una mediana mayor a 0, luego compararemos el resultado de este post-procesamiento con las clasificaciones reales del conjunto de test. Nuevamente, para este clasificador nos basaremos en la configuración paramétrica ya establecida en partes anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la prueba: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.63      0.94      0.76       331\n",
      "       True       0.89      0.50      0.64       357\n",
      "\n",
      "avg / total       0.77      0.71      0.69       688\n",
      "\n",
      "Accuracy general: 0.7078488372093024\n"
     ]
    }
   ],
   "source": [
    "clasificacionHumoristicoMediana = []\n",
    "for clasificacion in clasificacionCLFMediana:\n",
    "    clasificacionHumoristicoMediana += [clasificacion >=1]\n",
    "clasificacionOficial =[]\n",
    "for index, a in corpus_test.iterrows():\n",
    "    clasificacionOficial.append(a[\"humoristico\"])\n",
    "\n",
    "print(\"Resultados de la prueba: \")\n",
    "print(classification_report(clasificacionOficial, clasificacionHumoristicoMediana))\n",
    "\n",
    "acc = accuracy(clasificacionOficial, clasificacionHumoristicoMediana)\n",
    "print(\"Accuracy general: \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este clasificador en general obtenemos una precisión del 70% la cuál es un tanto inferior a los resultados del primer clasificador. Esta baja en la precisión se puede deber a que este clasificador arrastra las imprecisiones del clasificador por mediana. Estas imprecisiones se deben principalmente a que si bien el promedio y la varianza del error del clasificador por mediana es relativamente acotado aún así estos son considerables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
